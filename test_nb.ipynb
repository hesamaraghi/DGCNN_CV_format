{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "from collections import OrderedDict\n",
    "\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import model_factory\n",
    "import dataset_factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharaghi\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-GNN/DGCNN_CV_format/wandb/run-20221230_110716-125ts883</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/haraghi/DGCNN_CV_format/runs/125ts883\" target=\"_blank\">winter-sea-12</a></strong> to <a href=\"https://wandb.ai/haraghi/DGCNN_CV_format\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGCNN/ewrilqhd/checkpoints/epoch=161-step=66419.ckpt\n"
     ]
    }
   ],
   "source": [
    "exprement_number = 'ewrilqhd'\n",
    "batch_number = 'best'\n",
    "path_files = glob(osp.join('wandb','*-'+exprement_number,'files','config.yaml'))\n",
    "cfg = OmegaConf.load(path_files[0])\n",
    "cfg.dataset = cfg.dataset.value\n",
    "cfg.model = cfg.model.value\n",
    "cfg.optimize = cfg.optimize.value\n",
    "cfg.seed = cfg.seed.value\n",
    "cfg.train = cfg.train.value\n",
    "cfg.transform = cfg.transform.value\n",
    "cfg.wandb = cfg.wandb.value\n",
    "path_files = glob(osp.join(cfg.wandb.project,exprement_number,'checkpoints','*'))\n",
    "pl_ckpt_file = path_files[0]\n",
    "print(pl_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./artifacts/model-ewrilqhd:v161/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "artifact = run.use_artifact(osp.join(cfg.wandb.entity,cfg.wandb.project,f'model-{exprement_number}:{batch_number}'), type='model')\n",
    "artifact_dir = artifact.download()\n",
    "wandb_ckpt_file = osp.join(artifact_dir,'model.ckpt')\n",
    "print(wandb_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are pl and wandb the same? True\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(wandb_ckpt_file)\n",
    "ordered_list = [(a[6:],b) for a , b in checkpoint['state_dict'].items()]\n",
    "stated_dict_wandb = OrderedDict(ordered_list)\n",
    "\n",
    "checkpoint = torch.load(pl_ckpt_file)\n",
    "ordered_list = [(a[6:],b) for a , b in checkpoint['state_dict'].items()]\n",
    "stated_dict_pl = OrderedDict(ordered_list)\n",
    "\n",
    "is_same = all([torch.allclose(v,stated_dict_pl[c]) for c,v in stated_dict_wandb.items()])\n",
    "print(f'Are pl and wandb the same? {is_same}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train.batch_size = 32\n",
    "loaders = dataset_factory.factory(cfg)\n",
    "train_dataset_loader, val_dataset_loader, test_dataset_loader = loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32, 'ckpt_path': None, 'epochs': 500, 'profiler': 'simple'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cfg.model.name = \"DGCNN\"\n",
    "model_2knn = model_factory.factory(cfg).to(device)\n",
    "cfg.model.name = \"DGCNN2\"\n",
    "model_1knn = model_factory.factory(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out,_ = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            all_pred.append(pred)\n",
    "            all_true.append(data.y)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset), all_pred, all_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2knn.load_state_dict(stated_dict_pl)\n",
    "model_1knn.load_state_dict(stated_dict_pl)\n",
    "\n",
    "if not is_same:\n",
    "    model_2knn.state_dict(stated_dict_wandb)\n",
    "    model_1knn.state_dict(stated_dict_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 3.95 GiB total capacity; 2.59 GiB already allocated; 791.56 MiB free; 2.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     perf \u001b[39m=\u001b[39m test(test_dataset_loader, model_2knn)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(perf[\u001b[39m0\u001b[39m], perf[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;32m/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb Cell 11\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     out,_ \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     all_pred\u001b[39m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-GNN/DGCNN_CV_format/models/dgcnn.py:29\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m batch \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mbatch\n\u001b[1;32m     28\u001b[0m x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x0, batch)\n\u001b[0;32m---> 29\u001b[0m x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x1, batch)\n\u001b[1;32m     30\u001b[0m out1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin1(torch\u001b[39m.\u001b[39mcat([x1, x2], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     31\u001b[0m out2 \u001b[39m=\u001b[39m global_max_pool(out1, batch)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/edge_conv.py:138\u001b[0m, in \u001b[0;36mDynamicEdgeConv.forward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m knn(x[\u001b[39m0\u001b[39m], x[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, b[\u001b[39m0\u001b[39m], b[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mflip([\u001b[39m0\u001b[39m])\n\u001b[1;32m    137\u001b[0m \u001b[39m# propagate_type: (x: PairTensor)\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:317\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 317\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    318\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    319\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/edge_conv.py:141\u001b[0m, in \u001b[0;36mDynamicEdgeConv.message\u001b[0;34m(self, x_i, x_j)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_i: Tensor, x_j: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn(torch\u001b[39m.\u001b[39;49mcat([x_i, x_j \u001b[39m-\u001b[39;49m x_i], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 3.95 GiB total capacity; 2.59 GiB already allocated; 791.56 MiB free; 2.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    perf = test(test_dataset_loader, model_2knn)\n",
    "    print(perf[0], perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_dataset_loader.dataset\n",
    "dataset_idx = [x for x in range(len(dataset)) if dataset[x].label[0] == 'butterfly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2knn.eval()\n",
    "torch.cuda.empty_cache()\n",
    "out,inters = model_2knn(dataset[dataset_idx[0]].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 1], pos=[1024, 3], file_id='image_0014.bin', label=[1], y=[1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "sio.savemat('butterfly_image_0014.mat', {'pos': dataset[dataset_airplane_idx[0]].pos.cpu().numpy(), 'x1': inters['x1'].detach().cpu().numpy(),\n",
    "                                         'x2': inters['x2'].detach().cpu().numpy(), 'out1': inters['out1'].detach().cpu().numpy(), \n",
    "                                         'out2': inters['out2'].detach().cpu().numpy(),'out': inters['out'].detach().cpu().numpy()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x1', 'x2', 'out1', 'out2', 'out'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1s = []\n",
    "x2s = []\n",
    "out1s = []\n",
    "out2s = []\n",
    "for idx in dataset_airplane_idx:\n",
    "    out,inters = model_2knn(dataset[idx].to(device))\n",
    "    x1s.append(inters['x1'])\n",
    "    x2s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.37 GiB already allocated; 4.38 MiB free; 3.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blogin3/home/nfs/maraghi/mybulk/event-based-GNN/DGCNN_CV_format/test_nb.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     out,inters \u001b[39m=\u001b[39m model_2knn(data)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-GNN/DGCNN_CV_format/models/dgcnn.py:33\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m     out2 \u001b[39m=\u001b[39m global_max_pool(out1, batch)\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:       \n\u001b[0;32m---> 33\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x0)\n\u001b[1;32m     34\u001b[0m     x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x1)\n\u001b[1;32m     35\u001b[0m     out1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin1(torch\u001b[39m.\u001b[39mcat([x1, x2], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/edge_conv.py:138\u001b[0m, in \u001b[0;36mDynamicEdgeConv.forward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m knn(x[\u001b[39m0\u001b[39m], x[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, b[\u001b[39m0\u001b[39m], b[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mflip([\u001b[39m0\u001b[39m])\n\u001b[1;32m    137\u001b[0m \u001b[39m# propagate_type: (x: PairTensor)\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:317\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 317\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    318\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    319\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/conv/edge_conv.py:141\u001b[0m, in \u001b[0;36mDynamicEdgeConv.message\u001b[0;34m(self, x_i, x_j)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_i: Tensor, x_j: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn(torch\u001b[39m.\u001b[39;49mcat([x_i, x_j \u001b[39m-\u001b[39;49m x_i], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/models/mlp.py:143\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    142\u001b[0m     \u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlins[\u001b[39m0\u001b[39;49m](x)\n\u001b[1;32m    144\u001b[0m     \u001b[39mfor\u001b[39;00m lin, norm \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlins[\u001b[39m1\u001b[39m:], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms):\n\u001b[1;32m    145\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_first:\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/aegnn4/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py:118\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    114\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.37 GiB already allocated; 4.38 MiB free; 3.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for data in dataset_airplane:\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out,inters = model_2knn(data)\n",
    "    # dd.inters = inters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6331603701953643 0.6457564575645757\n",
      "8.8765177337006 0.3158671586715867\n",
      "1.4989483463012452 0.6880093131548312\n",
      "9.07915810295256 0.28754365541327126\n"
     ]
    }
   ],
   "source": [
    "perf_2 = test(test_dataset_loader, model_2knn)\n",
    "perf_1 = test(test_dataset_loader, model_1knn)\n",
    "print(perf_2[0], perf_2[1])\n",
    "print(perf_1[0], perf_1[1])\n",
    "perf_2 = test(val_dataset_loader, model_2knn)\n",
    "perf_1 = test(val_dataset_loader, model_1knn)\n",
    "print(perf_2[0], perf_2[1])\n",
    "print(perf_1[0], perf_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BACKGROUND_Google\n",
      "1 Faces_easy\n",
      "2 Leopards\n",
      "3 Motorbikes\n",
      "4 accordion\n",
      "5 airplanes\n",
      "6 anchor\n",
      "7 ant\n",
      "8 barrel\n",
      "9 bass\n",
      "10 beaver\n",
      "11 binocular\n",
      "12 bonsai\n",
      "13 brain\n",
      "14 brontosaurus\n",
      "15 buddha\n",
      "16 butterfly\n",
      "17 camera\n",
      "18 cannon\n",
      "19 car_side\n",
      "20 ceiling_fan\n",
      "21 cellphone\n",
      "22 chair\n",
      "23 chandelier\n",
      "24 cougar_body\n",
      "25 cougar_face\n",
      "26 crab\n",
      "27 crayfish\n",
      "28 crocodile\n",
      "29 crocodile_head\n",
      "30 cup\n",
      "31 dalmatian\n",
      "32 dollar_bill\n",
      "33 dolphin\n",
      "34 dragonfly\n",
      "35 electric_guitar\n",
      "36 elephant\n",
      "37 emu\n",
      "38 euphonium\n",
      "39 ewer\n",
      "40 ferry\n",
      "41 flamingo\n",
      "42 flamingo_head\n",
      "43 garfield\n",
      "44 gerenuk\n",
      "45 gramophone\n",
      "46 grand_piano\n",
      "47 hawksbill\n",
      "48 headphone\n",
      "49 hedgehog\n",
      "50 helicopter\n",
      "51 ibis\n",
      "52 inline_skate\n",
      "53 joshua_tree\n",
      "54 kangaroo\n",
      "55 ketch\n",
      "56 lamp\n",
      "57 laptop\n",
      "58 llama\n",
      "59 lobster\n",
      "60 lotus\n",
      "61 mandolin\n",
      "62 mayfly\n",
      "63 menorah\n",
      "64 metronome\n",
      "65 minaret\n",
      "66 nautilus\n",
      "67 octopus\n",
      "68 okapi\n",
      "69 pagoda\n",
      "70 panda\n",
      "71 pigeon\n",
      "72 pizza\n",
      "73 platypus\n",
      "74 pyramid\n",
      "75 revolver\n",
      "76 rhino\n",
      "77 rooster\n",
      "78 saxophone\n",
      "79 schooner\n",
      "80 scissors\n",
      "81 scorpion\n",
      "82 sea_horse\n",
      "83 snoopy\n",
      "84 soccer_ball\n",
      "85 stapler\n",
      "86 starfish\n",
      "87 stegosaurus\n",
      "88 stop_sign\n",
      "89 strawberry\n",
      "90 sunflower\n",
      "91 tick\n",
      "92 trilobite\n",
      "93 umbrella\n",
      "94 watch\n",
      "95 water_lilly\n",
      "96 wheelchair\n",
      "97 wild_cat\n",
      "98 windsor_chair\n",
      "99 wrench\n",
      "100 yin_yang\n"
     ]
    }
   ],
   "source": [
    "class_names = []\n",
    "for cc in range(101):\n",
    "    idx = np.where(test_dataset.data.y == cc)[0][0]   \n",
    "    class_names.append(test_dataset.data.label[idx][0])\n",
    "    print(test_dataset.data.y[idx].item(), test_dataset.data.label[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9a2feb1cc6493988fc7647709ae44e",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "y_true = torch.cat(all_true,dim=0).cpu().numpy()\n",
    "y_pred = torch.cat(all_pred,dim=0).cpu().numpy()\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "np.fill_diagonal(conf_mat, 0)\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 chair 22 BACKGROUND_Google 0\n",
      "4 lobster 59 BACKGROUND_Google 0\n",
      "4 watch 94 camera 17\n",
      "4 llama 58 kangaroo 54\n",
      "4 ibis 51 llama 58\n",
      "3 crocodile_head 29 crocodile 28\n",
      "3 helicopter 50 airplanes 5\n",
      "3 lotus 60 water_lilly 95\n",
      "3 BACKGROUND_Google 0 cup 30\n",
      "3 dolphin 33 bass 9\n",
      "3 soccer_ball 84 yin_yang 100\n",
      "3 BACKGROUND_Google 0 chair 22\n",
      "3 BACKGROUND_Google 0 camera 17\n",
      "3 schooner 79 ketch 55\n",
      "3 wheelchair 96 BACKGROUND_Google 0\n",
      "3 soccer_ball 84 BACKGROUND_Google 0\n",
      "2 stop_sign 88 BACKGROUND_Google 0\n",
      "2 buddha 15 sea_horse 82\n",
      "2 bass 9 electric_guitar 35\n",
      "2 pizza 72 BACKGROUND_Google 0\n"
     ]
    }
   ],
   "source": [
    "max_number = 20\n",
    "rows_sorted, columns_sorted = np.unravel_index(np.argsort(conf_mat.flatten())[::-1][:max_number], conf_mat.shape)\n",
    "for r,c in zip(rows_sorted,columns_sorted):\n",
    "    print(conf_mat[r,c],class_names[r],r,class_names[c],c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 6 6 1.0\n",
      "97 6 6 1.0\n",
      "44 6 6 1.0\n",
      "10 7 7 1.0\n",
      "24 8 8 1.0\n",
      "29 8 8 1.0\n",
      "9 8 9 0.8888888888888888\n",
      "28 7 8 0.875\n",
      "6 6 7 0.8571428571428571\n",
      "59 6 7 0.8571428571428571\n",
      "18 6 7 0.8571428571428571\n",
      "58 10 12 0.8333333333333334\n",
      "78 5 6 0.8333333333333334\n",
      "99 5 6 0.8333333333333334\n",
      "95 5 6 0.8333333333333334\n",
      "70 5 6 0.8333333333333334\n",
      "27 9 11 0.8181818181818182\n",
      "26 9 11 0.8181818181818182\n",
      "33 8 10 0.8\n",
      "82 7 9 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "max_number = 20\n",
    "num_classses = [torch.sum(test_dataset.data.y == i).item() for i in np.arange(101)]\n",
    "num_errors = np.sum(conf_mat,axis=1)\n",
    "sorted_vec = num_errors/num_classses\n",
    "# plt.stem(err_vec,linefmt = 'r:',markerfmt='rD')\n",
    "for ii in sorted_vec.argsort()[::-1][:max_number]:\n",
    "    print(ii,num_errors[ii],num_classses[ii],num_errors[ii]/num_classses[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 beaver\n",
      "24 cougar_body\n",
      "29 crocodile_head\n",
      "44 gerenuk\n",
      "62 mayfly\n",
      "97 wild_cat\n"
     ]
    }
   ],
   "source": [
    "for ii in np.where(np.diag(confusion_matrix(y_true, y_pred)) == 0)[0]:\n",
    "    print(ii,class_names[ii])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aegnn4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7506179fb4895bf173c92d050940f04115b110405b5093a64b29a8056d772c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
