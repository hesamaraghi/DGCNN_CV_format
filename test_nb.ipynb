{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "from collections import OrderedDict\n",
    "\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import model_factory\n",
    "import dataset_factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprement_number = 'ewrilqhd'\n",
    "batch_number = 'best'\n",
    "path_files = glob(osp.join('wandb','*-'+exprement_number,'files','config.yaml'))\n",
    "cfg = OmegaConf.load(path_files[0])\n",
    "cfg.dataset = cfg.dataset.value\n",
    "cfg.model = cfg.model.value\n",
    "cfg.optimize = cfg.optimize.value\n",
    "cfg.seed = cfg.seed.value\n",
    "cfg.train = cfg.train.value\n",
    "cfg.transform = cfg.transform.value\n",
    "cfg.wandb = cfg.wandb.value\n",
    "path_files = glob(osp.join(cfg.wandb.project,exprement_number,'checkpoints','*'))\n",
    "pl_ckpt_file = path_files[0]\n",
    "print(pl_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact(osp.join(cfg.wandb.entity,cfg.wandb.project,f'model-{exprement_number}:{batch_number}'), type='model')\n",
    "artifact_dir = artifact.download()\n",
    "wandb_ckpt_file = osp.join(artifact_dir,'model.ckpt')\n",
    "print(wandb_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(wandb_ckpt_file)\n",
    "ordered_list = [(a[6:],b) for a , b in checkpoint['state_dict'].items()]\n",
    "stated_dict_wandb = OrderedDict(ordered_list)\n",
    "\n",
    "checkpoint = torch.load(pl_ckpt_file)\n",
    "ordered_list = [(a[6:],b) for a , b in checkpoint['state_dict'].items()]\n",
    "stated_dict_pl = OrderedDict(ordered_list)\n",
    "\n",
    "is_same = all([torch.allclose(v,stated_dict_pl[c]) for c,v in stated_dict_wandb.items()])\n",
    "print(f'Are pl and wandb the same? {is_same}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train.batch_size = 32\n",
    "loaders = dataset_factory.factory(cfg)\n",
    "train_dataset_loader, val_dataset_loader, test_dataset_loader = loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cfg.model.name = \"DGCNN\"\n",
    "model_2knn = model_factory.factory(cfg).to(device)\n",
    "cfg.model.name = \"DGCNN2\"\n",
    "model_1knn = model_factory.factory(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out,_ = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            all_pred.append(pred)\n",
    "            all_true.append(data.y)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset), all_pred, all_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2knn.load_state_dict(stated_dict_pl)\n",
    "model_1knn.load_state_dict(stated_dict_pl)\n",
    "\n",
    "if not is_same:\n",
    "    model_2knn.state_dict(stated_dict_wandb)\n",
    "    model_1knn.state_dict(stated_dict_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    perf = test(test_dataset_loader, model_2knn)\n",
    "    print(perf[0], perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_dataset_loader.dataset\n",
    "dataset_idx = [x for x in range(len(dataset)) if dataset[x].label[0] == 'butterfly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2knn.eval()\n",
    "torch.cuda.empty_cache()\n",
    "out,inters = model_2knn(dataset[dataset_idx[0]].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "sio.savemat('butterfly_image_0014.mat', {'pos': dataset[dataset_airplane_idx[0]].pos.cpu().numpy(), 'x1': inters['x1'].detach().cpu().numpy(),\n",
    "                                         'x2': inters['x2'].detach().cpu().numpy(), 'out1': inters['out1'].detach().cpu().numpy(), \n",
    "                                         'out2': inters['out2'].detach().cpu().numpy(),'out': inters['out'].detach().cpu().numpy()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1s = []\n",
    "x2s = []\n",
    "out1s = []\n",
    "out2s = []\n",
    "for idx in dataset_airplane_idx:\n",
    "    out,inters = model_2knn(dataset[idx].to(device))\n",
    "    x1s.append(inters['x1'])\n",
    "    x2s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset_airplane:\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out,inters = model_2knn(data)\n",
    "    # dd.inters = inters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_2 = test(test_dataset_loader, model_2knn)\n",
    "perf_1 = test(test_dataset_loader, model_1knn)\n",
    "print(perf_2[0], perf_2[1])\n",
    "print(perf_1[0], perf_1[1])\n",
    "perf_2 = test(val_dataset_loader, model_2knn)\n",
    "perf_1 = test(val_dataset_loader, model_1knn)\n",
    "print(perf_2[0], perf_2[1])\n",
    "print(perf_1[0], perf_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "for cc in range(101):\n",
    "    idx = np.where(test_dataset.data.y == cc)[0][0]   \n",
    "    class_names.append(test_dataset.data.label[idx][0])\n",
    "    print(test_dataset.data.y[idx].item(), test_dataset.data.label[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "y_true = torch.cat(all_true,dim=0).cpu().numpy()\n",
    "y_pred = torch.cat(all_pred,dim=0).cpu().numpy()\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "np.fill_diagonal(conf_mat, 0)\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number = 20\n",
    "rows_sorted, columns_sorted = np.unravel_index(np.argsort(conf_mat.flatten())[::-1][:max_number], conf_mat.shape)\n",
    "for r,c in zip(rows_sorted,columns_sorted):\n",
    "    print(conf_mat[r,c],class_names[r],r,class_names[c],c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "max_number = 20\n",
    "num_classses = [torch.sum(test_dataset.data.y == i).item() for i in np.arange(101)]\n",
    "num_errors = np.sum(conf_mat,axis=1)\n",
    "sorted_vec = num_errors/num_classses\n",
    "# plt.stem(err_vec,linefmt = 'r:',markerfmt='rD')\n",
    "for ii in sorted_vec.argsort()[::-1][:max_number]:\n",
    "    print(ii,num_errors[ii],num_classses[ii],num_errors[ii]/num_classses[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.where(np.diag(confusion_matrix(y_true, y_pred)) == 0)[0]:\n",
    "    print(ii,class_names[ii])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aegnn4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7506179fb4895bf173c92d050940f04115b110405b5093a64b29a8056d772c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
