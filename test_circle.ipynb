{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm   \n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_circle(image_size,min_radius=10):\n",
    "\n",
    "\n",
    "    # Generate random circle parameters\n",
    "    while True:\n",
    "        center_x = random.randint(0, image_size[0] - 1)\n",
    "        center_y = random.randint(0, image_size[1] - 1)\n",
    "        c2border = min(center_x, center_y, image_size[0] - center_x, image_size[1] - center_y) \n",
    "        if c2border > min_radius:\n",
    "            break\n",
    "    \n",
    "    radius = random.randint(min_radius, min(center_x, center_y, image_size[0] - center_x, image_size[1] - center_y))\n",
    "    \n",
    "    return radius , center_x, center_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_circle(image_size,min_radius=10):\n",
    "    # Create a blank image\n",
    "    img = Image.new('L', image_size, color='black')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    radius , center_x, center_y  = calculate_circle(image_size,min_radius)\n",
    "    # Draw the circle on the image\n",
    "    draw.ellipse((center_x - radius, center_y - radius, center_x + radius, center_y + radius), outline='white', fill='black')\n",
    "\n",
    "    return img, radius , center_x, center_y\n",
    "\n",
    "\n",
    "# Generate a random circle\n",
    "img, radius , center_x, center_y = generate_random_circle(image_size=[224,224])\n",
    "\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSparsifyTransform:\n",
    "    def __init__(self, percent_change=0.1):\n",
    "        self.percent_change = percent_change\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to NumPy array\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Get the coordinates of black pixels\n",
    "        white_pixels = np.argwhere(img_array == 255)\n",
    "\n",
    "        # Randomly select a percentage of black pixels to change to white\n",
    "        if self.percent_change < 1.0:\n",
    "            num_pixels_to_keep = int(self.percent_change * len(white_pixels))\n",
    "        else:\n",
    "            num_pixels_to_keep = int(self.percent_change)\n",
    "            if num_pixels_to_keep > len(white_pixels):\n",
    "                num_pixels_to_keep = len(white_pixels)\n",
    "        selected_pixels = random.sample(range(len(white_pixels)), num_pixels_to_keep)   \n",
    "\n",
    "        sparse_img = np.zeros(img_array.shape, dtype = np.uint8)\n",
    "        # Change the selected black pixels to white\n",
    "        self.coords = []\n",
    "        for idx in selected_pixels:\n",
    "            x, y = white_pixels[idx]\n",
    "            self.coords.append([x,y])\n",
    "            sparse_img[x, y] = 255  # White color\n",
    "\n",
    "        # Convert NumPy array back to PIL image\n",
    "        # transformed_img = Image.fromarray(img_array)\n",
    "\n",
    "        return sparse_img, np.array(self.coords,dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Generate a random circle\n",
    "img, radius , center_x, center_y = generate_random_circle(image_size=[224,224])\n",
    "\n",
    "display(img)\n",
    "display(Image.fromarray(RandomSparsifyTransform(percent_change=10)(img)[0],mode='L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size\n",
    "image_size = (224, 224)\n",
    "all_r = []\n",
    "for i in range(1000000):\n",
    "    r,_,_ = calculate_circle(image_size,min_radius=10)\n",
    "    all_r.append(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r = np.array(all_r)\n",
    "np.sum(all_r>21)/np.size(all_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPCircleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPCircleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc15 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming x is a tensor of shape (batch_size, 3, 2) for three 2D coordinates\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # Pass through the first fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = F.relu(self.fc15(x))\n",
    "        # Pass through the second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 6  # 3 coordinates with 2 values each\n",
    "hidden_size = 64\n",
    "output_size = 1  # Binary classification\n",
    "\n",
    "model = MLPCircleClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Generate dummy input data\n",
    "dummy_input = torch.rand((32, 3, 2))  # Batch size of 32\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNCircleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNCircleClassifier, self).__init__()\n",
    "        self.resnet34 = models.get_model('resnet34', weights=\"DEFAULT\")\n",
    "        self.resnet34.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet34.fc = nn.Linear(self.resnet34.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class StupidCircleClassifier(nn.Module):\n",
    "    def __init__(self,b):\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = -torch.ones([x.shape[0],1], dtype=torch.float32, device=x.device)\n",
    "        self.max_d = torch.zeros([x.shape[0],1], dtype=torch.float32, device=x.device)\n",
    "        for i in range(x.shape[0]):\n",
    "           \n",
    "            self.max_d[i] = self.max_distance(x[i])\n",
    "            if self.max_d[i] > 2*self.b:\n",
    "                outputs[i] = 1.0\n",
    "        return outputs\n",
    "\n",
    "    def max_distance(self, coordinates):\n",
    "        # Calculate pair-wise distances\n",
    "        distances = torch.cdist(coordinates, coordinates)\n",
    "\n",
    "        # Set diagonal elements to zero since they represent distances between the same points\n",
    "        distances.fill_diagonal_(0)\n",
    "\n",
    "        # Find the maximum distance\n",
    "        max_dist = distances.max()\n",
    "\n",
    "        return max_dist.item()\n",
    "\n",
    "# Example usage\n",
    "N = 5  # replace with the actual size of your tensor\n",
    "coordinates = torch.rand(5,N, 2)*42  # replace with your actual tensor\n",
    "\n",
    "model = StupidCircleClassifier(b = 21)\n",
    "model.eval()\n",
    "out = model(coordinates)\n",
    "print(f\"Maximum distance between coordinates: {model.max_d}\")\n",
    "print(f\"Output: {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CircleDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size, b, transform=None):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.b = b\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate a random circle image\n",
    "        circle_image, radius , center_x, center_y = generate_random_circle(self.image_size)\n",
    "        \n",
    "        # Apply the transform if provided\n",
    "        if self.transform:\n",
    "            img, coords = self.transform(circle_image)\n",
    "\n",
    "        # Convert PIL image to PyTorch tensor\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        img = transform(img)\n",
    "        coords = torch.tensor(coords)\n",
    "\n",
    "        # Calculate the label\n",
    "        label = 1 if radius > self.b else 0\n",
    "        return img, coords, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mlp_test = False\n",
    "# Set parameters\n",
    "num_samples = 1000\n",
    "image_size = (224, 224)\n",
    "b = 21  # Choose a predefined radius\n",
    "number_pixel_to_keep = 10\n",
    "input_size = 2 * number_pixel_to_keep\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "# Example usage with the transform\n",
    "transform = transforms.Compose([\n",
    "    RandomSparsifyTransform(percent_change=number_pixel_to_keep),\n",
    "])\n",
    "\n",
    "# Create a dataset and DataLoader\n",
    "circle_dataset = CircleDataset(num_samples, image_size, b, transform=transform)\n",
    "dataloader = DataLoader(circle_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "model_mlp = MLPCircleClassifier(input_size, hidden_size, output_size).to(device)\n",
    "model_cnn = CNNCircleClassifier().to(device)\n",
    "models_all = [model_mlp,model_cnn]\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_mlp = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "optimizers_all = [optimizer_mlp,optimizer_cnn]\n",
    "\n",
    "\n",
    "# Add cosine annealing learning rate scheduler\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "scheduler_mlp = lr_scheduler.ReduceLROnPlateau(optimizer_mlp, mode='min', patience=10, factor=0.5, verbose=True)\n",
    "scheduler_cnn = lr_scheduler.ReduceLROnPlateau(optimizer_cnn, mode='min', patience=10, factor=0.5, verbose=True)\n",
    "schedulers_all = [scheduler_mlp,scheduler_cnn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_loss = []\n",
    "    correct_predictions = []\n",
    "    current_lr = []\n",
    "    total_samples = 0\n",
    "    for _ in range(len(models_all)):\n",
    "        correct_predictions.append(0)\n",
    "        total_loss.append(0.0)\n",
    "        current_lr.append(0.0)\n",
    "\n",
    "    for imgs, coords, labels in tqdm(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        coords = coords.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Zero the parameter gradients\n",
    "        for optimizer in optimizers_all:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        for i, model in enumerate(models_all):\n",
    "            if 'CNN' in model._get_name():\n",
    "                outputs = model(imgs)\n",
    "            else:\n",
    "                outputs = model(coords)\n",
    "        \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "            # Backward pass and optimization\n",
    "  \n",
    "            loss.backward()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5)\n",
    "            correct_predictions[i] += (predictions == labels.view(-1, 1)).sum().item()\n",
    "            total_loss[i] += loss.item()\n",
    "        \n",
    "        for optimizer in optimizers_all:\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Accumulate the total loss\n",
    "        \n",
    "\n",
    "    # Get the current learning rate from the optimizer\n",
    "    for i, optimizer in enumerate(optimizers_all):\n",
    "        current_lr[i] = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = [t / len(dataloader) for t in total_loss]\n",
    "    accuracy = [c / total_samples for c in correct_predictions]\n",
    "    \n",
    "    for i, scheduler in enumerate(schedulers_all):\n",
    "        scheduler.step(avg_loss[i])\n",
    "    \n",
    "    for i in range(len(models_all)):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Model: {models_all[i]._get_name()}, Loss: {avg_loss[i]:.4f}, Accuracy: {accuracy[i]:.4f}, Learning Rate: {current_lr[i]:.6f}')\n",
    "    \n",
    "    # print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Learning Rate: {current_lr:.6f}')\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "for model in models_all:\n",
    "    torch.save(model.state_dict(), f'{model._get_name()}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create a test dataset and DataLoader\n",
    "model_cnn = CNNCircleClassifier().to(device)\n",
    "model_mlp = MLPCircleClassifier(input_size, hidden_size, output_size).to(device)\n",
    "model_cnn.load_state_dict(torch.load(model_cnn._get_name()+'.pth'))\n",
    "model_mlp.load_state_dict(torch.load(model_mlp._get_name()+'.pth'))\n",
    "model_stupid = StupidCircleClassifier(b = 21).to(device)\n",
    "models_all = [model_cnn, model_mlp, model_stupid]\n",
    "\n",
    "test_dataset = CircleDataset(num_samples=10000, image_size=image_size, b=b, transform=RandomSparsifyTransform(percent_change=2))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluation loop\n",
    "for model in models_all:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "total_correct = []\n",
    "total_samples = 0\n",
    "\n",
    "for _ in models_all:\n",
    "    total_correct.append(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, coords, labels in test_dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        coords = coords.to(device)\n",
    "        labels = labels.to(device)  \n",
    "        # Forward pass\n",
    "        # Forward pass\n",
    "        for i, model in enumerate(models_all):\n",
    "            if 'CNN' in model._get_name():\n",
    "                outputs = model(imgs)\n",
    "            else:\n",
    "                outputs = model(coords)\n",
    "        \n",
    "\n",
    "            # Compute accuracy\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5)\n",
    "            total_correct[i] += (predictions == labels.view(-1, 1)).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "for i in range(len(models_all)):\n",
    "    test_accuracy = total_correct[i] / total_samples\n",
    "    print(f'Test Accuracy {i} for {models_all[i]._get_name()}: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    def __init__(self, module, device=None):\n",
    "        # we are going to hook some model's layer (module here)\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.device = device\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        # when the module.forward() is executed, here we intercept its\n",
    "        # input and output. We are interested in the module's output.\n",
    "        self.features = output.clone()\n",
    "        if self.device is not None:\n",
    "            self.features = self.features.to(self.device)\n",
    "        self.features.requires_grad_(True)\n",
    "\n",
    "    def close(self):\n",
    "        # we must call this method to free memory resources\n",
    "        self.hook.remove()\n",
    "        del self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = [        SaveFeatures(model.resnet34.relu,device=device),\n",
    "                        SaveFeatures(model.resnet34.layer1[-1],device=device),\n",
    "                        SaveFeatures(model.resnet34.layer2[-1],device=device),\n",
    "                        SaveFeatures(model.resnet34.layer3[-1],device=device),\n",
    "                        SaveFeatures(model.resnet34.layer4[-1],device=device)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, radius , center_x, center_y = generate_random_circle(image_size=[224,224])\n",
    "print('Radius is {}'.format(radius))\n",
    "\n",
    "\n",
    "fm_transform = RandomSparsifyTransform(percent_change=3)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    tensor_1 = transforms.ToTensor()(fm_transform(img))\n",
    "    out_1 = model(tensor_1.unsqueeze(0).to(device))\n",
    "\n",
    "    # Compute accuracy\n",
    "    prediction = (torch.sigmoid(out_1) > 0.5)\n",
    "    print('Prediction: R > 21? {}'.format(prediction.item()))\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "tensor_1[0,...] = tensor_1[0,...]/(torch.max(tensor_1[0,...])+1e-8)\n",
    "plt.imshow((tensor_1[0,...]), cmap='viridis')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tensor = feature_maps[0].features.clone().detach().cpu().numpy()\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    tensor[0,i,...] = tensor[0,i,...]/(np.max(tensor[0,i,...], axis=None)+1e-8)\n",
    "    plt.imshow(tensor[0,i,...], cmap='viridis')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "tensor = feature_maps[1].features.clone().detach().cpu().numpy()\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+ 1)\n",
    "    tensor[0,i,...] = tensor[0,i,...]/(np.max(tensor[0,i,...], axis=None)+1e-8)\n",
    "    plt.imshow(tensor[0,i,...], cmap='viridis')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "tensor = feature_maps[2].features.clone().detach().cpu().numpy()\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4 , i+ 1)\n",
    "    tensor[0,i,...] = tensor[0,i,...]/(np.max(tensor[0,i,...], axis=None)+1e-8)\n",
    "    plt.imshow(tensor[0,i,...], cmap='viridis')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "tensor = feature_maps[3].features.clone().detach().cpu().numpy()\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5 , i+ 1)\n",
    "    tensor[0,i,...] = tensor[0,i,...]/(np.max(tensor[0,i,...], axis=None)+1e-8)\n",
    "    plt.imshow(tensor[0,i,...], cmap='viridis')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "tensor = feature_maps[4].features.clone().detach().cpu().numpy()\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(36):\n",
    "    plt.subplot(6,6 , i+ 1)\n",
    "    tensor[0,i,...] = tensor[0,i,...]/(np.max(tensor[0,i,...], axis=None)+1e-8)\n",
    "    # plt.pcolor(tensor[0,i,...], cmap='viridis', vmin=0, vmax=1)\n",
    "    plt.imshow(tensor[0,i,...], cmap='viridis')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fm in feature_maps:\n",
    "    fm.close()\n",
    "    \n",
    "    # plt.hist(fm.features.view(-1).clone().detach().cpu().numpy(), bins=100)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "sparsify = RandomSparsifyTransform(percent_change=2)\n",
    "\n",
    "\n",
    "r_and_c = []\n",
    "for i in range(10000):\n",
    "    img, radius , center_x, center_y = generate_random_circle(image_size=[224,224])\n",
    "    img_sparse = sparsify(img)\n",
    "\n",
    "    # Get the coordinates of the non-zero pixels\n",
    "    nonzero_pixels = np.argwhere(img_sparse != 0)\n",
    "    \n",
    "    # Calculate the pairwise distances between the non-zero pixels\n",
    "    assert len(sparsify.coords) == 2, \"The transform should only keep 2 pixels\"\n",
    "    \n",
    "    # Calculate the Euclidean distance between the two coordinates\n",
    "    distance = euclidean(sparsify.coords[0], sparsify.coords[1])\n",
    "    r_and_c.append([radius, distance])\n",
    "    \n",
    "    \n",
    "r_and_c = np.array(r_and_c)\n",
    "# sort r_and_c by second column\n",
    "sorted_r_and_c = r_and_c[r_and_c[:,1].argsort()]\n",
    "ind_r_big = sorted_r_and_c[:,0]>21\n",
    "ind_r_small = sorted_r_and_c[:,0]<=21\n",
    "ind_d_big = sorted_r_and_c[:,1]>42\n",
    "ind_d_small = sorted_r_and_c[:,1]<=42\n",
    "same_big = ind_d_big & ind_r_big\n",
    "same_small = ind_d_small & ind_r_small\n",
    "same_big.sum() + same_small.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted_r_and_c[:,1], sorted_r_and_c[:,0], '.')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sorted_r_and_c[ind_r_big,1], bins=100)\n",
    "plt.hist(sorted_r_and_c[ind_r_small,1], bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
