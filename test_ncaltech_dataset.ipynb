{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import model_factory\n",
    "from graph_data_module import GraphDataModule\n",
    "from train import Runner\n",
    "from datasets.dataset_factory import create_dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "artifact_dir = WandbLogger.download_artifact(artifact=\"haraghi/DGCNN/model-0gmu6xyw:best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"0gmu6xyw\"\n",
    "entity = \"haraghi\"\n",
    "project = \"DGCNN\"\n",
    "cfg_path = \"cfg_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EST_NCALTECH101_1024_ShuffleNet_250epoch_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024_ShuffleNet_250epoch_remove_outliers_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024_not_pretrained_Rsnet18.yaml\n",
      "EST_NCALTECH101_1024_MobileNet_250epoch_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024_ShuffleNet_500epoch_batch_32_remove_outliers_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024_MobileNet_250epoch_remove_outliers_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024_not_pretrained.yaml\n",
      "EST_NCALTECH101_1024.yaml\n"
     ]
    }
   ],
   "source": [
    "method = \"EST\"\n",
    "dataset = \"NCALTECH101\"\n",
    "sampling_number = '1024'\n",
    "\n",
    "res = [f for f in os.listdir(cfg_path) if method in f and dataset in f and sampling_number in f]\n",
    "for f in res:\n",
    "    print(f)\n",
    "pre_cfg_path = osp.join(cfg_path,res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_cfg_path = osp.join(cfg_path,res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0gmu6xyw\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "if run_id is None:\n",
    "    runs = api.runs(\n",
    "        path=osp.join(entity,project),\n",
    "        filters={\"config.wandb.experiment_name\": {\"$regex\": f\"^.*{method}.*{sampling_number}.*$\"}},\n",
    "        # filters={\"config.wandb.experiment_name\": {\"$regex\": \"^.*EST-aug 20000.*$\"}}\n",
    "    )\n",
    "    print([l.id for l in runs])\n",
    "    run_id = runs[0].id\n",
    "    \n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharaghi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hesam/Projects/DGCNN_CV_format/wandb/run-20230905_130608-vb3qvoaf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/haraghi/DGCNN_CV_format/runs/vb3qvoaf' target=\"_blank\">quiet-flower-5</a></strong> to <a href='https://wandb.ai/haraghi/DGCNN_CV_format' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/haraghi/DGCNN_CV_format' target=\"_blank\">https://wandb.ai/haraghi/DGCNN_CV_format</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/haraghi/DGCNN_CV_format/runs/vb3qvoaf' target=\"_blank\">https://wandb.ai/haraghi/DGCNN_CV_format/runs/vb3qvoaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "checkpoint_reference = osp.join(entity, project, \"model-\" + run_id+\":best\")\n",
    "artifact = run.use_artifact(checkpoint_reference, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "\n",
    "config = api.run(osp.join(entity, project, run_id)).config\n",
    "cfg = OmegaConf.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: ' Applying EST on NCALTECH101 with subsampling 1024 and NOT pretrained\n",
      "  shufflenet_v2_x0_5 for 500 epoch. And, batch size is 32. Remove outliers. Only the\n",
      "  learning sceduler is slightly different.'\n",
      "seed: 0\n",
      "optimize:\n",
      "  optimizer: Adam\n",
      "  lr: 0.0001\n",
      "  lr_scheduler: ReduceLROnPlateau\n",
      "  mode: min\n",
      "  factor: 0.5\n",
      "  patience: 10\n",
      "model:\n",
      "  name: EST\n",
      "  k: null\n",
      "  aggr: ''\n",
      "  num_bins: 9\n",
      "  cnn_type: shufflenet_v2_x0_5\n",
      "  resnet_crop_dimension:\n",
      "  - 224\n",
      "  - 224\n",
      "  est_mlp_layers:\n",
      "  - 1\n",
      "  - 30\n",
      "  - 30\n",
      "  - 1\n",
      "  est_activation: nn.LeakyReLU(negative_slope=0.1)\n",
      "  resnet_pretrained: false\n",
      "train:\n",
      "  epochs: 500\n",
      "  batch_size: 32\n",
      "  loss_fn: nn.CrossEntropyLoss()\n",
      "  profiler: simple\n",
      "  ckpt_path: null\n",
      "dataset:\n",
      "  name: NCALTECH101\n",
      "  train_percentage: 0.75\n",
      "  validation_percentage: 0.1\n",
      "  image_resolution:\n",
      "  - 180\n",
      "  - 240\n",
      "  num_samples_per_class: null\n",
      "  num_classes: 101\n",
      "  dataset_path: null\n",
      "  num_workers: 8\n",
      "transform:\n",
      "  train:\n",
      "    transform: true\n",
      "    spatial_centering: null\n",
      "    temporal_scale: null\n",
      "    num_events_per_sample: 1024\n",
      "    random_flip: null\n",
      "    scale_limits: null\n",
      "    degree_limit: null\n",
      "    thresh_quantile: 0.3\n",
      "    conv_vec_path: datasets/NCALTECH101/conv_scores\n",
      "    radius_graph:\n",
      "      transform: null\n",
      "      r: 3\n",
      "      max_num_neighbors: 32\n",
      "      add_edge_attr:\n",
      "        transform: null\n",
      "        cat: nul\n",
      "    shift_and_flip:\n",
      "      transform: true\n",
      "      max_shift: 20\n",
      "      p: 0.5\n",
      "  validation:\n",
      "    transform: true\n",
      "    spatial_centering: null\n",
      "    temporal_scale: null\n",
      "    num_events_per_sample: 1024\n",
      "    random_flip: null\n",
      "    scale_limits: null\n",
      "    degree_limit: null\n",
      "    thresh_quantile: 0.3\n",
      "    conv_vec_path: datasets/NCALTECH101/conv_scores\n",
      "    radius_graph:\n",
      "      transform: null\n",
      "      r: 3\n",
      "      max_num_neighbors: 32\n",
      "      add_edge_attr:\n",
      "        transform: null\n",
      "        cat: null\n",
      "    shift_and_flip:\n",
      "      transform: null\n",
      "      max_shift: 20\n",
      "      p: 0.5\n",
      "  test:\n",
      "    transform: true\n",
      "    spatial_centering: null\n",
      "    temporal_scale: null\n",
      "    num_events_per_sample: 1024\n",
      "    random_flip: null\n",
      "    scale_limits: null\n",
      "    degree_limit: null\n",
      "    thresh_quantile: 0.3\n",
      "    conv_vec_path: datasets/NCALTECH101/conv_scores\n",
      "    radius_graph:\n",
      "      transform: null\n",
      "      r: 3\n",
      "      max_num_neighbors: 32\n",
      "      add_edge_attr:\n",
      "        transform: null\n",
      "        cat: null\n",
      "    shift_and_flip:\n",
      "      transform: null\n",
      "      max_shift: 20\n",
      "      p: 0.5\n",
      "wandb:\n",
      "  log: true\n",
      "  dir: ./\n",
      "  experiment_name: EST 1024 shufflenet_v2_x0_5 500 epochs batch 32 with outlier removal\n",
      "    (not pretrained)\n",
      "  entity: haraghi\n",
      "  project: DGCNN\n",
      "cfg_path: cfg_folder/EST_NCALTECH101_1024_ShuffleNet_500epoch_batch_32_remove_outliers_not_pretrained.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_file = OmegaConf.load(pre_cfg_path)\n",
    "cfg = OmegaConf.merge(cfg_file, cfg)\n",
    "# cfg = cfg_file\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.transform.train.transform = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "# Seed everything. Note that this does not make training entirely\n",
    "# deterministic.\n",
    "pl.seed_everything(cfg.seed, workers=True)\n",
    "\n",
    "\n",
    "# Create datasets using factory pattern\n",
    "gdm = GraphDataModule(cfg)\n",
    "cfg.dataset.num_classes = gdm.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = create_dataset(\n",
    "        dataset_path = gdm.dataset_path,\n",
    "        dataset_name  = gdm.dataset_name,\n",
    "        dataset_type = 'training',\n",
    "        transform = None,\n",
    "        num_workers=gdm.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for data in ds:\n",
    "    \n",
    "    vals, args = data.pos[:,:2].max(axis=0)\n",
    "    max_list.append(vals)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for data in ds:\n",
    "    if data.file_id == 'image_0048.bin' and data.label[0] == 'kangaroo':\n",
    "        data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[109377, 1], pos=[109377, 3], file_id='image_0048.bin', label=[1], y=[1])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.9600e+02, 1.7200e+02, 3.0081e+05]),\n",
       "indices=tensor([   180,    492, 109376]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].pos.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 ns ± 13.9 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "%timeit x.long()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
