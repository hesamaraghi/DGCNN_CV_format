{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "api = wandb.Api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = api.projects(entity=\"haraghi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    print(project.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join('images','clustering_metric')\n",
    "save_folder_paper = os.path.join('images','paper','clustering_metric')\n",
    "\n",
    "# runs = list(api.runs(\"haraghi/EST-DVSGESTURE-HP-sweep\"))\n",
    "# save_folder = os.path.join(save_folder,'DVS_GESTURE')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'DVS_GESTURE')\n",
    "\n",
    "# runs = list(api.runs(\"sweep EST (FAN1VS3) (multi val test num 20)\"))\n",
    "# runs += list(api.runs(\"sweep EST (FAN1VS3) 25000 (multi val test num 20)\"))\n",
    "\n",
    "# runs = list(api.runs(\"sweep_EST_NCALTECH101_256_multi20\"))\n",
    "# runs += list(api.runs(\"sweep_EST_NCALTECH101_1024_multi20\"))\n",
    "# runs += list(api.runs(\"sweep_EST_NCALTECH101_25000_multi20\"))\n",
    "# save_folder = os.path.join(save_folder,'NCALTECH101')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'NCALTECH101')\n",
    "\n",
    "# runs =api.runs(\"haraghi/EST-NASL-HP-sweep\")\n",
    "# save_folder = os.path.join(save_folder,'NASL')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'NASL')\n",
    "\n",
    "## FINAL EXPERIMENTS:\n",
    "\n",
    "# runs = api.runs(\"haraghi/FINAL-FAN1VS3-HP-sweep-reduced\")\n",
    "# save_folder = os.path.join(save_folder,'FAN1VS3')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'FAN1VS3')\n",
    "\n",
    "# runs = list(api.runs(\"FINAL-DVSGESTURE_TONIC-HP-sweep-reduced\"))\n",
    "# save_folder = os.path.join(save_folder,'DVS_GESTURE_TONIC')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'DVS_GESTURE_TONIC')\n",
    "\n",
    "# runs = list(api.runs(\"FINAL-NCALTECH101-HP-sweep-reduced\"))\n",
    "# save_folder = os.path.join(save_folder,'NCALTECH101')\n",
    "# save_folder_paper = os.path.join(save_folder_paper,'NCALTECH101')\n",
    "\n",
    "runs =api.runs(\"haraghi/FINAL-NASL-HP-sweep-reduced\")\n",
    "save_folder = os.path.join(save_folder,'NASL')\n",
    "save_folder_paper = os.path.join(save_folder_paper,'NASL')\n",
    "\n",
    "print(len(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [r for r in runs if r.state == \"finished\"]\n",
    "print(len(runs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = np.unique([run.config['transform']['train']['num_events_per_sample'] for run in runs])\n",
    "runs_per_num_events = {num_event: [run for run in runs if run.config['transform']['train']['num_events_per_sample'] == num_event] for num_event in num_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs_per_num_events[256] = [runs_per_num_events[256][idx] for idx in  np.random.choice(len(runs_per_num_events[256]), 200, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_val_and_test_acc_keys(run):\n",
    "    val_acc_key = []\n",
    "    test_acc_key = []\n",
    "    for key in run.summary.keys():\n",
    "        if \"val\" in key and \"acc\" in key and \"mean\" in key:\n",
    "            val_acc_key.append(key)\n",
    "        if \"test\" in key and \"acc\" in key and \"mean\" in key:\n",
    "            test_acc_key.append(key)\n",
    "    assert len(val_acc_key) <= 1, f\"More than one val acc key found: {val_acc_key}\"\n",
    "    assert len(test_acc_key) <= 1, f\"More than one test acc key found: {test_acc_key}\"\n",
    "    return val_acc_key[0] if len(val_acc_key) == 1 else None , test_acc_key[0] if len(test_acc_key) == 1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mean = {}\n",
    "test_mean = {}\n",
    "for num_event in num_events:\n",
    "    val_mean[num_event] = []\n",
    "    test_mean[num_event] = []\n",
    "    for run in runs_per_num_events[num_event]:\n",
    "        val_key, test_key = find_val_and_test_acc_keys(run)\n",
    "        val_mean[num_event].append(run.summary[val_key] if val_key is not None and val_key in run.summary else None)\n",
    "        test_mean[num_event].append(run.summary[test_key] if test_key is not None and test_key in run.summary else None)\n",
    "    \n",
    "for num_event in num_events:\n",
    "    print(f\"percentage of runs with val acc for {num_event} events: {np.sum([v is not None for v in val_mean[num_event]]) / len(val_mean[num_event])} out of {len(val_mean[num_event])} runs\")\n",
    "    print(f\"percentage of runs with test acc for {num_event} events: {np.sum([v is not None for v in test_mean[num_event]]) / len(test_mean[num_event])} out of {len(test_mean[num_event])} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_paper = [np.max(num_events), np.min(num_events)]\n",
    "\n",
    "input_case = [ \"dense\", \"sparse\"]\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(5,4))\n",
    "\n",
    "for i, num_event in enumerate(num_events_paper):\n",
    "    # ax[i].hist([[vm for vm in val_mean[num_event] if vm is not None], \n",
    "    #           [tm for tm in test_mean[num_event] if tm is not None]], \n",
    "    #          bins=50, range=(0, 1), label=['val', 'test'])\n",
    "    ax[i].hist([vm for vm in val_mean[num_event] if vm is not None],  bins=50, alpha=0.5, label='val.', range=(0,1) ,edgecolor='none', density=True )\n",
    "    ax[i].hist([tm for tm in test_mean[num_event] if tm is not None], bins=100, alpha=0.5, label='test', range=(0,1) ,edgecolor='none', density=True )\n",
    "    ax[i].set_title(f'{input_case[i]} input: {num_event} events per sample', fontsize=16)\n",
    "    ax[i].set_yticks([]) \n",
    "    ax[i].grid(axis='x', linestyle='--', alpha=0.5)  # Add pale and dashed grid lines along the x-axis\n",
    "    # ax[i].set_ylabel('Frequency')\n",
    "    ax[i].set_xticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])  # Remove x-axis ticks\n",
    "    ax[i].tick_params(axis='both', labelsize=14)  # Set tick label font size      \n",
    "    ax[i].legend(fontsize=14)\n",
    "\n",
    "ax[i].set_xlabel('Test Accuracy', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(save_folder_paper):\n",
    "    os.makedirs(save_folder_paper)\n",
    "plt.savefig(os.path.join(save_folder_paper, f'both_events_per_sample.png'))    \n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "# Show the figure\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_paper = [np.max(num_events), np.min(num_events)]\n",
    "\n",
    "input_case = [ \"dense\", \"sparse\"]\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(5,4))\n",
    "\n",
    "for i, num_event in enumerate(num_events_paper):\n",
    "    ax[i].hist([[vm for vm in val_mean[num_event] if vm is not None], \n",
    "              [tm for tm in test_mean[num_event] if tm is not None]], \n",
    "             bins=50, range=(0, 1), label=['val', 'test'])\n",
    "    ax[i].set_title(f'{input_case[i]} input: {num_event} events per sample')\n",
    "    ax[i].set_xlabel('Accuracy')\n",
    "    ax[i].set_ylabel('Frequency')\n",
    "    ax[i].legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(save_folder_paper):\n",
    "    os.makedirs(save_folder_paper)\n",
    "plt.savefig(os.path.join(save_folder_paper, f'both_events_per_sample.eps'), format='eps')    \n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "# Show the figure\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_event in num_events:\n",
    "    \n",
    "    plt.hist([[vm for vm in val_mean[num_event] if vm is not None], \n",
    "              [tm for tm in test_mean[num_event] if tm is not None]], \n",
    "             bins=50, range=(0., 1), label=['val', 'test'])\n",
    "    plt.title(f'{num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    \n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    plt.savefig(os.path.join(save_folder, f'{num_event}_events_per_sample.png'))    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comopute_cluster_dis(data, K=5):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Reshape data for KMeans clustering\n",
    "    X = data.reshape(-1, 1)\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=K,  random_state=42,n_init='auto')\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Assign each data point to a cluster\n",
    "    labels = kmeans.labels_\n",
    "    centers = np.squeeze(kmeans.cluster_centers_)\n",
    "\n",
    "    # Find the cluster with the maximum value\n",
    "    max_cluster_center = np.max(centers)\n",
    "\n",
    "    # Find the cluster with the most samples\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    most_samples_cluster_index = np.argmax(counts)\n",
    "    most_samples_cluster_center = centers[unique_labels[most_samples_cluster_index]]\n",
    "\n",
    "    # Compute the difference between the centers\n",
    "    center_difference = abs(max_cluster_center - most_samples_cluster_center)\n",
    "\n",
    "    return center_difference\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val = {}\n",
    "metric_test = {}\n",
    "K = 10\n",
    "print('Validation accuracy')\n",
    "for num_event in num_events:\n",
    "    print(f'Number of events: {num_event}')\n",
    "    data = np.array([vm for vm in val_mean[num_event] if vm is not None])\n",
    "    center_difference = []\n",
    "    for k in range(2, K):\n",
    "        \n",
    "        center_difference.append(comopute_cluster_dis(data, k)/np.max(data))\n",
    "        print(f'Center difference for {num_event} events and K={k}: {center_difference[-1]}')\n",
    "    print(f'maximum center difference for {num_event} events: {np.max(center_difference)}')\n",
    "    plt.plot(range(2, K), center_difference, label=f'{num_event} events')\n",
    "    metric_val[num_event] = (center_difference, np.max(data), np.mean(data))\n",
    "plt.title('Normalized center difference for validation accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Normalized center difference')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder, 'center_difference_val.png'))\n",
    "plt.show()\n",
    "\n",
    "print('Test accuracy')\n",
    "for num_event in num_events:\n",
    "    print(f'Number of events: {num_event}')\n",
    "    data = np.array([tm for tm in test_mean[num_event] if tm is not None])\n",
    "    center_difference = []\n",
    "    for k in range(2, K):\n",
    "        \n",
    "        center_difference.append(comopute_cluster_dis(data, k)/np.max(data))\n",
    "        print(f'Center difference for {num_event} events and K={k}: {center_difference[-1]}')\n",
    "    print(f'maximum center difference for {num_event} events: {np.max(center_difference)}')\n",
    "    plt.plot(range(2, K), center_difference, label=f'{num_event} events')\n",
    "    metric_test[num_event] = (center_difference, np.max(data), np.mean(data))\n",
    "plt.title('Normalized center difference for test accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Normalized center difference')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder, 'center_difference_test.png'))\n",
    "plt.show()\n",
    "clustering_metric = {'val': metric_val, 'test': metric_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(save_folder_paper,\"clustering_metric.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(clustering_metric, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 8\n",
    "for num_event in num_events:\n",
    "\n",
    "    data = np.array([vm for vm in test_mean[num_event] if vm is not None])\n",
    "\n",
    "    # Compute histogram\n",
    "    hist, bins = np.histogram(data, bins=20)   \n",
    "    \n",
    "    # Find mode (bin with highest frequency)\n",
    "    mode_value = bins[np.argmax(hist)]\n",
    "\n",
    "    # Find maximum value in data\n",
    "    max_value = np.max(data)\n",
    "    mean_value = np.mean(data) \n",
    "    # Compute distance between max value and mode \n",
    "    print(\"Mode acc.:\", mode_value)\n",
    "    print(\"Mean acc.:\", mean_value)\n",
    "    print(\"Maximum acc.:\", max_value)\n",
    "    distance = abs(max_value - mode_value)\n",
    "    print(\"Distance between max and mode:\", distance)\n",
    "    normalized_distance = distance / max_value\n",
    "    print(\"Normalized distance:\", normalized_distance)\n",
    "    print(\"Cluster-based normalized distance:\", comopute_cluster_dis(data, K)/max_value)\n",
    "    \n",
    "\n",
    "    # Reshape data for KMeans clustering\n",
    "    X = data.reshape(-1, 1)\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=K, random_state=42,n_init='auto')\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Plot histogram with clusters\n",
    "    for i in range(K):\n",
    "        cluster_data = data[labels == i]\n",
    "        hist, _ = np.histogram(cluster_data, bins=bins)\n",
    "        plt.bar(bins[:-1], hist, width=np.diff(bins), edgecolor='black', alpha=0.5, label=f'Cluster {i+1}')\n",
    "\n",
    "    plt.xlabel(f'Accuracy \\nDistance between max and mode: {distance}\\nNormalized distance: {normalized_distance}\\nCluster-based normalized distance: {comopute_cluster_dis(data, K)/max_value}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Clustered Bins for {num_event} events')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_folder, f'clustered_bins_{num_event}.png'), bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
