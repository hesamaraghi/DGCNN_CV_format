{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HDF5_PLUGIN_PATH\"] = '/usr/lib/x86_64-linux-gnu/hdf5/serial/plugins'\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import  Data\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from event_utils.lib.data_formats.event_packagers import hdf5_packager\n",
    "from event_utils.lib.data_formats.read_events import read_h5_events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array_by_window(arr, t_len):\n",
    "    # Sort the input array by timestamps if it's not already sorted\n",
    "\n",
    "\n",
    "    # Find the minimum and maximum timestamps\n",
    "    min_timestamp, max_timestamp = arr.min(), arr.max()\n",
    "\n",
    "    # Calculate the number of windows required\n",
    "    num_windows = int(np.ceil((max_timestamp - min_timestamp) / t_len))\n",
    "\n",
    "    # Initialize a list to store the split arrays\n",
    "    split_arrays = []\n",
    "    split_indexes = []\n",
    "\n",
    "    # Iterate through the windows and split the array\n",
    "    for i in tqdm(range(num_windows)):\n",
    "        window_start = min_timestamp + i * t_len\n",
    "        window_end = min_timestamp + (i + 1) * t_len\n",
    "\n",
    "        # Extract elements within the current window\n",
    "        split_index = np.where((arr >= window_start) & (arr < window_end))[0]\n",
    "        split_indexes.append(split_index)\n",
    "        window_array = arr[split_index] - window_start\n",
    "\n",
    "        if len(window_array) > 0:\n",
    "            split_arrays.append(window_array)\n",
    "\n",
    "    return split_arrays,split_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = '../datasets/led'\n",
    "classes = glob.glob(os.path.join(download_path , '*'))\n",
    "hdf5_pathes = glob.glob(os.path.join(download_path , '*/*.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_list = []\n",
    "split_arrays_list = []\n",
    "split_indexes_list = []\n",
    "num_events_list = []\n",
    "t_len = 74000 # in micro seconds\n",
    "for hdf5_path in hdf5_pathes:\n",
    "    print(hdf5_path)\n",
    "    class_name = os.path.dirname(hdf5_path).split(os.path.sep)[-1]\n",
    "    dir_path = os.path.dirname(hdf5_path).replace('full_video','segmented')\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        \n",
    "    with h5py.File(hdf5_path, \"r\") as f:\n",
    "        evts = f[\"CD\"][\"events\"][()]\n",
    "          \n",
    "        timestamps = evts['t']\n",
    "        split_arrays,split_indexes = split_array_by_window(timestamps, t_len)\n",
    "        split_arrays_list.append(split_arrays)\n",
    "        split_indexes_list.append(split_indexes)\n",
    "        \n",
    "        evts_windows = []\n",
    "        for i in range(len(split_arrays)):\n",
    "            idx = split_indexes[i]\n",
    "            assert len(idx) == len(split_arrays[i])\n",
    "            evts_window = evts[idx]\n",
    "            evts_window['t'] = split_arrays[i]\n",
    "            evts_windows.append(evts_window)\n",
    "            \n",
    "            file_name = f'{class_name}_{i:04d}.hdf5'\n",
    "            hdf5_path = os.path.join(dir_path,file_name)\n",
    "              \n",
    "            packager = hdf5_packager(hdf5_path)\n",
    "            packager.package_events(evts_window['x'],evts_window['y'],evts_window['t'],evts_window['p'])\n",
    "            \n",
    "            num_pos = np.sum(evts_window['p'] == 1)\n",
    "            num_neg = np.sum(evts_window['p'] == 0)\n",
    "            t0 = evts_window['t'][0]\n",
    "            tk = evts_window['t'][-1]\n",
    "            duration = tk - t0\n",
    "            num_imgs = 0\n",
    "            num_flow = 0\n",
    "            sensor_size = [1280, 720]\n",
    "            \n",
    "            packager.add_metadata(num_pos, num_neg, duration, t0, tk, num_imgs, num_flow, sensor_size)\n",
    "                     \n",
    "            packager.events_file.close()\n",
    "            \n",
    "        evt_list.append(evts_windows)\n",
    "        \n",
    "        num_events = np.array([len(split_arrays[i]) for i in range(len(split_arrays))])\n",
    "        num_events_list.append(num_events)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 89\n",
    "class_name = os.path.dirname(hdf5_path).split(os.path.sep)[-1]\n",
    "dir_path = os.path.join(os.path.dirname(hdf5_path),class_name)\n",
    "file_name = f'{class_name}_{i:04d}.hdf5'\n",
    "file_path = os.path.join(dir_path,file_name)\n",
    "print(file_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "events = read_h5_events_dict('datasets_torch_geometric/fan1vs3/data/raw/all/speed_1/speed_1_0000.hdf5', read_frames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = events['xs'].astype(np.float32)\n",
    "data_y = events['ys'].astype(np.float32)\n",
    "data_ts = events['ts'].astype(np.float32)    \n",
    "data_p = events['ps'].astype(np.float32)\n",
    "\n",
    "pos = np.array([data_x,data_y,data_ts])\n",
    "pos = torch.from_numpy(pos)\n",
    "pos = pos.transpose(0,1)\n",
    "data_p = torch.from_numpy(data_p)\n",
    "data = Data(x=data_p,pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms of arrays in 'num_events_list' in one figure with defferent colors\n",
    "\n",
    "for i in range(len(num_events_list)):\n",
    "    plt.hist(num_events_list[i], bins=100, alpha=0.5, label=classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
