{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "api = wandb.Api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = api.projects(entity=\"haraghi\")\n",
    "for project in projects:\n",
    "    print(project.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_name = 'HP_vs_acc'\n",
    "dataset_name = 'NASL'\n",
    "save_folder = os.path.join('images',subfolder_name,dataset_name)\n",
    "save_folder_paper = os.path.join('images','paper',subfolder_name,dataset_name)\n",
    "\n",
    "if dataset_name == 'DVSGESTURE_TONIC':\n",
    "    # runs = api.runs(\"haraghi/EST-DVSGESTURE-HP-sweep\")\n",
    "    runs = api.runs(\"FINAL-DVSGESTURE_TONIC-HP-sweep-reduced\")\n",
    "elif dataset_name == 'FAN1VS3':\n",
    "    # runs = list(api.runs(\"haraghi/sweep EST (FAN1VS3) (multi val test num 20)\"))\n",
    "    # runs += list(api.runs(\"haraghi/sweep EST (FAN1VS3) 25000 (multi val test num 20)\"))\n",
    "    runs = list(api.runs(\"FINAL-FAN1vs3-HP-sweep-reduced\"))\n",
    "elif dataset_name == 'NCALTECH101':\n",
    "    runs = api.runs(\"FINAL-NCALTECH101-HP-sweep-reduced\")\n",
    "    # runs = list(api.runs(\"haraghi/sweep_EST_NCALTECH101_1024_multi20\"))\n",
    "    # runs += list(api.runs(\"haraghi/sweep_EST_NCALTECH101_25000_multi20\"))\n",
    "    # runs += list(api.runs(\"haraghi/sweep_EST_NCALTECH101_256_multi20\"))  \n",
    "elif dataset_name == 'NASL':\n",
    "    # runs =api.runs(\"haraghi/EST-NASL-HP-sweep\")\n",
    "    runs =api.runs(\"FINAL-NASL-HP-sweep-reduced\")\n",
    "else:\n",
    "    raise ValueError('Dataset name not recognized')\n",
    "\n",
    "print(len(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [r for r in runs if r.state == \"finished\"]\n",
    "print(len(runs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = np.unique([run.config['transform']['train']['num_events_per_sample'] for run in runs])\n",
    "print(num_events)\n",
    "runs_per_num_events = {num_event: [run for run in runs if run.config['transform']['train']['num_events_per_sample'] == num_event] for num_event in num_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_val_and_test_acc_keys(run):\n",
    "    val_acc_key = []\n",
    "    test_acc_key = []\n",
    "    for key in run.summary.keys():\n",
    "        if \"val\" in key and \"acc\" in key and \"mean\" in key:\n",
    "            val_acc_key.append(key)\n",
    "        if \"test\" in key and \"acc\" in key and \"mean\" in key:\n",
    "            test_acc_key.append(key)\n",
    "    assert len(val_acc_key) <= 1, f\"More than one val acc key found: {val_acc_key}\"\n",
    "    assert len(test_acc_key) <= 1, f\"More than one test acc key found: {test_acc_key}\"\n",
    "    return val_acc_key[0] if len(val_acc_key) == 1 else None , test_acc_key[0] if len(test_acc_key) == 1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mean = {}\n",
    "test_mean = {}\n",
    "lr = {}\n",
    "batch_size = {}\n",
    "weight_decay = {}\n",
    "for num_event in num_events:\n",
    "    val_mean[num_event] = []\n",
    "    test_mean[num_event] = []\n",
    "    lr[num_event] = []\n",
    "    batch_size[num_event] = []\n",
    "    weight_decay[num_event] = []\n",
    "    for run in runs_per_num_events[num_event]:\n",
    "        val_key, test_key = find_val_and_test_acc_keys(run)\n",
    "        if val_key is None or test_key is None:\n",
    "            continue\n",
    "        val_mean[num_event].append(run.summary[val_key] if val_key in run.summary else None)\n",
    "        test_mean[num_event].append(run.summary[test_key] if test_key in run.summary else None)\n",
    "        lr[num_event].append(run.config['optimize']['lr'])\n",
    "        batch_size[num_event].append(run.config['train']['batch_size'])\n",
    "        if 'weight_decay' in run.config['optimize']:\n",
    "            weight_decay[num_event].append(run.config['optimize']['weight_decay'])\n",
    "    \n",
    "for num_event in num_events:\n",
    "    print(f\"percentage of runs with val acc for {num_event} events: {np.sum([v is not None for v in val_mean[num_event]]) / len(val_mean[num_event])} out of {len(val_mean[num_event])} runs\")\n",
    "    print(f\"percentage of runs with test acc for {num_event} events: {np.sum([v is not None for v in test_mean[num_event]]) / len(test_mean[num_event])} out of {len(test_mean[num_event])} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([l for l in lr[num_event] if l is not None]))\n",
    "print(len([tm for tm in test_mean[num_event] if tm is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_paper = [np.max(num_events), np.min(num_events)]\n",
    "\n",
    "input_case = [ \"dense\", \"sparse\"]\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(3, 4))\n",
    "\n",
    "for i, num_event in enumerate(num_events_paper):\n",
    "    \n",
    "    # Create a DataFrame from the data  \n",
    "    data = pd.DataFrame({'Learning Rate': [l for l in lr[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Learning Rate')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Learning Rate', y='Accuracy', data=data, ax=ax[i], boxprops=dict(facecolor=\"skyblue\"))\n",
    "    ax[i].set_title(f'{input_case[i]} input')\n",
    "    # if i == 0:\n",
    "        # ax[i].set_xticks([])\n",
    "        # ax[i].set_xlabel()\n",
    "        # for minor ticks\n",
    "        # ax[i].set_xticks([], minor=True)\n",
    "    \n",
    "    ax[i].set_xlabel('Learning rate')\n",
    "    # Modify the y-axis tick labels to scientific notation\n",
    "    # ax[i].tick_params(axis='y', rotation=90)\n",
    "    # ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=90)\n",
    "    ax[i].set_xticklabels([\"{:.1e}\".format(float(lr.get_text())).replace(\"e-0\",\"e-\") for lr in ax[i].get_xticklabels()], rotation=90)\n",
    "\n",
    "    if i == 0:  \n",
    "        ax[i].tick_params(labelbottom=False) \n",
    "        ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel('Test Accuracy')\n",
    "    ax[i].plot(mean_accuracy['Accuracy'].values, marker='o', color='blue', label='Test Mean Accuracy', alpha=0.7)\n",
    "    # ax[i].legend()\n",
    "\n",
    "# fig.suptitle(f'Learning rate: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(save_folder_paper):\n",
    "    os.makedirs(save_folder_paper)\n",
    "plt.savefig(os.path.join(save_folder_paper, f'lr_{dataset_name}_events_per_sample.png'))    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_event in num_events:\n",
    "    fig,ax = plt.subplots(1,2, figsize=(15,3))\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame from the data\n",
    "    data = pd.DataFrame({'Learning Rate': [l for l in lr[num_event] if l is not None], 'Accuracy': [vm for vm in val_mean[num_event] if vm is not None]})\n",
    "    mean_accuracy = data.groupby('Learning Rate')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Learning Rate', y='Accuracy', data=data, ax=ax[0])\n",
    "    ax[0].set_title(f'validation')\n",
    "    ax[0].set_xlabel('Learning rate')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Val. Mean Accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    data = pd.DataFrame({'Learning Rate': [l for l in lr[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Learning Rate')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Learning Rate', y='Accuracy', data=data, ax=ax[1])\n",
    "    ax[1].set_title(f'test')\n",
    "    ax[1].set_xlabel('Learning rate')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Test Mean Accuracy')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    fig.suptitle(f'Learning rate: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "    \n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    plt.savefig(os.path.join(save_folder, f'lr_{num_event}_events_per_sample.png'))    \n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_paper = [np.max(num_events), np.min(num_events)]\n",
    "\n",
    "input_case = [ \"dense\", \"sparse\"]\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(3, 4))\n",
    "\n",
    "for i, num_event in enumerate(num_events_paper):\n",
    "    \n",
    "    # Create a DataFrame from the data  \n",
    "    data = pd.DataFrame({'Batch size': [l for l in batch_size[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Batch size')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Batch size', y='Accuracy', data=data, ax=ax[i], boxprops=dict(facecolor=\"skyblue\"))\n",
    "    ax[i].set_title(f'{input_case[i]} input')\n",
    "    ax[i].set_xlabel('Batch size')\n",
    "    ax[i].set_ylabel('Test Accuracy')\n",
    "    \n",
    "    # Modify the y-axis tick labels to scientific notation\n",
    "    # ax[i].tick_params(axis='y', rotation=90)\n",
    "    # ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=90)\n",
    "    # ax[i].set_xticklabels([\"{:.1e}\".format(float(lr.get_text())).replace(\"e-0\",\"e-\") for lr in ax[i].get_xticklabels()], rotation=90)\n",
    "\n",
    "    if i == 0:  \n",
    "        ax[i].tick_params(labelbottom=False) \n",
    "        ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel('Test Accuracy')\n",
    "    ax[i].plot(mean_accuracy['Accuracy'].values, marker='o', color='blue', label='Test Mean Accuracy', alpha=0.7)\n",
    "    # ax[i].legend()\n",
    "\n",
    "# fig.suptitle(f'Learning rate: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(save_folder_paper):\n",
    "    os.makedirs(save_folder_paper)\n",
    "plt.savefig(os.path.join(save_folder_paper, f'BS_{dataset_name}_events_per_sample.png'))    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_event in num_events:\n",
    "    fig,ax = plt.subplots(1,2, figsize=(15,3))\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame from the data\n",
    "    data = pd.DataFrame({'Batch size': [l for l in batch_size[num_event] if l is not None], 'Accuracy': [vm for vm in val_mean[num_event] if vm is not None]})\n",
    "    mean_accuracy = data.groupby('Batch size')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Batch size', y='Accuracy', data=data, ax=ax[0])\n",
    "    ax[0].set_title(f'validation')\n",
    "    ax[0].set_xlabel('Batch size')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Val. Mean Accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    data = pd.DataFrame({'Batch size': [l for l in batch_size[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Batch size')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Batch size', y='Accuracy', data=data, ax=ax[1])\n",
    "    ax[1].set_title(f'test')\n",
    "    ax[1].set_xlabel('Batch size')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Test Mean Accuracy')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    fig.suptitle(f'Batch size: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "    \n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    plt.savefig(os.path.join(save_folder, f'batch_size_{num_event}_events_per_sample.png'))    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_paper = [np.max(num_events), np.min(num_events)]\n",
    "\n",
    "input_case = [ \"dense\", \"sparse\"]\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(2, 1, figsize=(3, 4))\n",
    "\n",
    "for i, num_event in enumerate(num_events_paper):\n",
    "    \n",
    "    \n",
    "        \n",
    "    data = pd.DataFrame({'Weight decay': [l for l in weight_decay[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Weight decay')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Weight decay', y='Accuracy', data=data, ax=ax[i], boxprops=dict(facecolor=\"skyblue\"))\n",
    "    ax[i].set_title(f'{input_case[i]} input')\n",
    "    ax[i].set_xlabel('Weight decay')\n",
    "    ax[i].set_ylabel('Test Accuracy')\n",
    "    # ax[i].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Test Mean Accuracy')\n",
    "    \n",
    "    # Modify the y-axis tick labels to scientific notation\n",
    "    # ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=90)\n",
    "    xticklabels = []\n",
    "    for lr in ax[i].get_xticklabels():\n",
    "        label_value = float(lr.get_text())\n",
    "        if label_value == 0:\n",
    "            xticklabels.append('0')\n",
    "        else:\n",
    "            xticklabels.append(\"{:.1e}\".format(label_value).replace(\"e-0\",\"e-\"))\n",
    "    ax[i].set_xticklabels(xticklabels, rotation=90)\n",
    "\n",
    "    if i == 0:  \n",
    "        ax[i].tick_params(labelbottom=False) \n",
    "        ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel('Test Accuracy')\n",
    "    ax[i].plot(mean_accuracy['Accuracy'].values, marker='o', color='blue', label='Test Mean Accuracy', alpha=0.7)\n",
    "    # ax[i].legend()\n",
    "\n",
    "# fig.suptitle(f'Learning rate: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(save_folder_paper):\n",
    "    os.makedirs(save_folder_paper)\n",
    "plt.savefig(os.path.join(save_folder_paper, f'WD_{dataset_name}_events_per_sample.png'))    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_event in num_events:\n",
    "    fig,ax = plt.subplots(1,2, figsize=(15,3))\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame from the data\n",
    "    data = pd.DataFrame({'Weight decay': [l for l in weight_decay[num_event] if l is not None], 'Accuracy': [vm for vm in val_mean[num_event] if vm is not None]})\n",
    "    mean_accuracy = data.groupby('Weight decay')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Weight decay', y='Accuracy', data=data, ax=ax[0])\n",
    "    ax[0].set_title(f'validation')\n",
    "    ax[0].set_xlabel('Weight decay')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Val. Mean Accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    data = pd.DataFrame({'Weight decay': [l for l in weight_decay[num_event] if l is not None], 'Accuracy': [tm for tm in test_mean[num_event] if tm is not None]})\n",
    "    mean_accuracy = data.groupby('Weight decay')['Accuracy'].mean().reset_index()\n",
    "    sns.boxplot(x='Weight decay', y='Accuracy', data=data, ax=ax[1])\n",
    "    ax[1].set_title(f'test')\n",
    "    ax[1].set_xlabel('Weight decay')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].plot(mean_accuracy['Accuracy'].values, marker='o', color='red', label='Test Mean Accuracy')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    fig.suptitle(f'Weight decay: {num_event} events per sample for {len(val_mean[num_event])} runs')\n",
    "    \n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    plt.savefig(os.path.join(save_folder, f'weight_decay_{num_event}_events_per_sample.png'))    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
