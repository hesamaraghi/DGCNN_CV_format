{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets_torch_geometric.dataset_factory import create_dataset\n",
    "import pickle\n",
    "from scipy.stats import binomtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_name_and_num_classes = {\n",
    "    # \"NCARS\": {\"name\": \"N-Cars\", \"num_classes\": 2},\n",
    "    \"NASL\": {\"name\": \"N-ASL\", \"num_classes\": 24},\n",
    "    \"FAN1VS3\": {\"name\": \"Fan1vs3\", \"num_classes\": 2},\n",
    "    \"DVS_GESTURE_TONIC\": {\"name\": \"DVS-Gesture\", \"num_classes\": 11},\n",
    "    \"NCALTECH101\": {\"name\": \"N-Caltech101\", \"num_classes\": 101},\n",
    "}\n",
    "subfolder = os.path.join(\"images\", \"paper\", \"clustering_metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_metric = {}\n",
    "for dataset_name in datasets_name_and_num_classes.keys():\n",
    "    with open(os.path.join(subfolder,dataset_name,\"clustering_metric.pkl\"), \"rb\") as f:\n",
    "        clustering_metric[dataset_name] = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric = {}\n",
    "for dataset_name  in datasets_name_and_num_classes.keys():\n",
    "    max_clustering_metric[dataset_name] = {}\n",
    "    for key, val in clustering_metric[dataset_name].items():\n",
    "        max_clustering_metric[dataset_name][key] = {}\n",
    "        for k, v in val.items():\n",
    "            assert isinstance(v[0], list), f\"val is not a list but {type(v[0])}\"\n",
    "            assert len(v) > 0, f\"val is empty\"\n",
    "            max_clustering_metric[dataset_name][key][k] = (np.max(v[0]),v[1],v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_p_value_md(file_path, p_values, num_events_list, datasets_name_and_num_classes):\n",
    "    # Open file for writing\n",
    "    with open(file_path, \"w\") as file:\n",
    "        # Write table header\n",
    "  \n",
    "\n",
    "\n",
    "        file.write(\"| Dataset | # classes | \" +\n",
    "                   \" | \".join([str(num_events) for num_events in num_events_list]) +\n",
    "                   \"\\n\")\n",
    "        file.write(\"| --- \"*(2+len(num_events_list))+\"|\\n\")\n",
    "        # Write table rows\n",
    "        for dataset, values in p_values.items():\n",
    "            row = \"| \" + datasets_name_and_num_classes[dataset][\"name\"] + \" | \" \n",
    "            # Number of classes\n",
    "            row += str(datasets_name_and_num_classes[dataset][\"num_classes\"]) + \" | \"\n",
    "            # Test accuracies\n",
    "            for v in values:\n",
    "                if v is not None:\n",
    "                    row += \"${:.2e}$\".format(v) + \" | \"\n",
    "                else:\n",
    "                    row += \"-- | \"\n",
    "            # Write the row\n",
    "            file.write(row[:-2] + \"|\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric_table = {}\n",
    "for dataset_name, values in max_clustering_metric.items(): \n",
    "    num_events = list(values['test'].keys())\n",
    "    assert num_events == list(values['val'].keys()), f\"num_events list are different for dataset {dataset_name}\"\n",
    "    max_clustering_metric_table[dataset_name] = {}\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"] = {}\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"num_events\"] = np.min(num_events)\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"val_metric\"] = max_clustering_metric[dataset_name][\"val\"][np.min(num_events)][0]\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"test_metric\"] = max_clustering_metric[dataset_name][\"test\"][np.min(num_events)][0]\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"val_max\"] = max_clustering_metric[dataset_name][\"val\"][np.min(num_events)][1]\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"test_max\"] = max_clustering_metric[dataset_name][\"test\"][np.min(num_events)][1]\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"val_mean\"] = max_clustering_metric[dataset_name][\"val\"][np.min(num_events)][2]\n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"test_mean\"] = max_clustering_metric[dataset_name][\"test\"][np.min(num_events)][2]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"] = {}\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"num_events\"] = np.max(num_events)\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"val_metric\"] = max_clustering_metric[dataset_name][\"val\"][np.max(num_events)][0]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"test_metric\"] = max_clustering_metric[dataset_name][\"test\"][np.max(num_events)][0]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"val_max\"] = max_clustering_metric[dataset_name][\"val\"][np.max(num_events)][1]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"test_max\"] = max_clustering_metric[dataset_name][\"test\"][np.max(num_events)][1]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"val_mean\"] = max_clustering_metric[dataset_name][\"val\"][np.max(num_events)][2]\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"test_mean\"] = max_clustering_metric[dataset_name][\"test\"][np.max(num_events)][2]\n",
    "    \n",
    "    max_clustering_metric_table[dataset_name][\"sparse\"][\"max_to_mean\"] = max_clustering_metric_table[dataset_name][\"sparse\"][\"test_max\"]/max_clustering_metric_table[dataset_name][\"sparse\"][\"test_mean\"] - 1\n",
    "    max_clustering_metric_table[dataset_name][\"dense\"][\"max_to_mean\"] = max_clustering_metric_table[dataset_name][\"dense\"][\"test_max\"]/max_clustering_metric_table[dataset_name][\"dense\"][\"test_mean\"] - 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric_table_string = {}\n",
    "for dataset_name, values in max_clustering_metric_table.items(): \n",
    "    max_clustering_metric_table_string[dataset_name] = {}\n",
    "    max_clustering_metric_table_string[dataset_name][\"sparse\"] = {}\n",
    "    max_clustering_metric_table_string[dataset_name][\"dense\"] = {}\n",
    "    max_clustering_metric_table_string[dataset_name][\"sparse\"][\"num_events\"] = str(values[\"sparse\"][\"num_events\"])\n",
    "    max_clustering_metric_table_string[dataset_name][\"dense\"][\"num_events\"] = str(values[\"dense\"][\"num_events\"])\n",
    "    if values[\"sparse\"][\"val_metric\"] >= values[\"dense\"][\"val_metric\"]:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"val_metric\"] = \"\\\\textbf{{{:.3f}}}\".format(values[\"sparse\"][\"val_metric\"])\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"val_metric\"] = \"{:.3f}\".format(values[\"dense\"][\"val_metric\"])\n",
    "    else:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"val_metric\"] = \"{:.3f}\".format(values[\"sparse\"][\"val_metric\"])\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"val_metric\"] = \"\\\\textbf{{{:.3f}}}\".format(values[\"dense\"][\"val_metric\"])\n",
    "    if values[\"sparse\"][\"test_metric\"] >= values[\"dense\"][\"test_metric\"]:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"test_metric\"] = \"\\\\textbf{{{:.3f}}}\".format(values[\"sparse\"][\"test_metric\"])\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"test_metric\"] = \"{:.3f}\".format(values[\"dense\"][\"test_metric\"])\n",
    "    else:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"test_metric\"] = \"{:.3f}\".format(values[\"sparse\"][\"test_metric\"])\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"test_metric\"] = \"\\\\textbf{{{:.3f}}}\".format(values[\"dense\"][\"test_metric\"])\n",
    "    max_clustering_metric_table_string[dataset_name][\"sparse\"][\"test_max\"] = \"{:.2f}\".format(values[\"sparse\"][\"test_max\"] * 100)\n",
    "    max_clustering_metric_table_string[dataset_name][\"dense\"][\"test_max\"] = \"{:.2f}\".format(values[\"dense\"][\"test_max\"] * 100)\n",
    "    max_clustering_metric_table_string[dataset_name][\"sparse\"][\"test_mean\"] = \"{:.2f}\".format(values[\"sparse\"][\"test_mean\"] * 100)\n",
    "    max_clustering_metric_table_string[dataset_name][\"dense\"][\"test_mean\"] = \"{:.2f}\".format(values[\"dense\"][\"test_mean\"] * 100)    \n",
    "    if values[\"sparse\"][\"max_to_mean\"] >= values[\"dense\"][\"max_to_mean\"]:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"max_to_mean\"] = \"\\\\textbf{{{:.2f}}}\".format(values[\"sparse\"][\"max_to_mean\"] * 100)\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"max_to_mean\"] = \"{:.2f}\".format(values[\"dense\"][\"max_to_mean\"] * 100)\n",
    "    else:\n",
    "        max_clustering_metric_table_string[dataset_name][\"sparse\"][\"max_to_mean\"] = \"{:.2f}\".format(values[\"sparse\"][\"max_to_mean\"] * 100)\n",
    "        max_clustering_metric_table_string[dataset_name][\"dense\"][\"max_to_mean\"] = \"\\\\textbf{{{:.2f}}}\".format(values[\"dense\"][\"max_to_mean\"] * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clustering_metric_table_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metric(file_path, max_clustering_metric_table, datasets_name_and_num_classes):\n",
    "    # Open file for writing\n",
    "    with open(file_path, \"w\") as file:\n",
    "        # Write table header\n",
    "        file.write(\"\\\\begin{tabular}{\"+\"l\"+(\"c\"*(2*len(max_clustering_metric_table)))+\"}\\n\")\n",
    "        file.write(\"\\\\toprule\\n\")\n",
    "        file.write(\"Dataset & \" + \n",
    "                   \" & \".join([\"\\\\multicolumn{2}{c}{\" + datasets_name_and_num_classes[k][\"name\"] + \"}\" for k in max_clustering_metric_table.keys()]) +\n",
    "                   \"\\\\\\\\\\n\")\n",
    "        file.write(\" & \" + \n",
    "                   \" & \".join([r\"\\small{dense} & \\small{sparse}\" for _ in max_clustering_metric_table.keys()]) +\n",
    "                   \"\\\\\\\\\\n\") \n",
    "        file.write(\"\\\\small{\\\\# events} & \" + \n",
    "                   \" & \".join([f\"\\\\small{{{v['dense']['num_events']}}} & \\\\small{{{v['sparse']['num_events']}}}\" for v in max_clustering_metric_table.values()]) +\n",
    "                   \"\\\\\\\\\\n\") \n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "        file.write(\"val. metric & \" + \n",
    "                   \" & \".join([\"{:.3f} & {:.3f}\".format(v['dense']['val_metric'],v['sparse']['val_metric']) for v in max_clustering_metric_table.values()]) +\n",
    "                   \"\\\\\\\\\\n\")     \n",
    "        file.write(\"test metric & \" + \n",
    "                   \" & \".join([\"{:.3f} & {:.3f}\".format(v['dense']['test_metric'],v['sparse']['test_metric']) for v in max_clustering_metric_table.values()]) +\n",
    "                   \"\\\\\\\\\\n\")                    \n",
    "        file.write(\"\\\\bottomrule\\n\")\n",
    "        file.write(\"\\\\end{tabular}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metric_and_max_mean(file_path, max_clustering_metric_table_string, datasets_name_and_num_classes):\n",
    "    # Open file for writing\n",
    "    with open(file_path, \"w\") as file:\n",
    "        # Write table header\n",
    "        file.write(\"\\\\begin{tabular}{\"+\"l\"+r\"c@{\\hskip 0.75in}\".join([\"cc\" for _ in range(len(max_clustering_metric_table_string))])+\"}\\n\")\n",
    "        file.write(\"\\\\toprule\\n\")\n",
    "        file.write(\"Dataset & \" + \n",
    "                   \" & & \".join([\"\\\\multicolumn{2}{c}{\" + datasets_name_and_num_classes[k][\"name\"] + \"}\" for k in max_clustering_metric_table_string.keys()]) +\n",
    "                   \"\\\\\\\\\")\n",
    "        file.write(\" \".join([f\"\\\\cmidrule{{{3*i+2}-{3*i+3}}}\" for i in range(len(max_clustering_metric_table_string))]) + \"\\n\")\n",
    "        file.write(\" & \" + \n",
    "                   \" & & \".join([r\"\\small{dense} & \\small{sparse}\" for _ in max_clustering_metric_table_string.keys()]) +\n",
    "                   \"\\\\\\\\\\n\") \n",
    "        file.write(\"\\\\small{\\\\# events} & \" + \n",
    "                   \" & & \".join([r\"\\small{\" + v['dense']['num_events'] + \"} & \" + r\"\\small{\" + v['sparse']['num_events'] + \"}\" for v in max_clustering_metric_table_string.values()]) +\n",
    "                   \"\\\\\\\\\\n\") \n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "        file.write(f\"\\\\multicolumn{{{3*len(max_clustering_metric_table)}}}{{c}}{{\\\\textbf{{Hyperparameter sensitivity metric}}}}\\\\\\\\\\n\")\n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "        file.write(\"val. metric & \" + \n",
    "                   \" & & \".join([v['dense']['val_metric'] + \" & \" + v['sparse']['val_metric'] for v in max_clustering_metric_table_string.values()]) +\n",
    "                   \"\\\\\\\\\\n\")     \n",
    "        file.write(\"test metric & \" + \n",
    "                   \" & & \".join([v['dense']['test_metric'] + \" & \" + v['sparse']['test_metric'] for v in max_clustering_metric_table_string.values()]) +\n",
    "                   \"\\\\\\\\\\n\")                    \n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "        file.write(f\"\\\\multicolumn{{{3*len(max_clustering_metric_table)}}}{{c}}{{\\\\textbf{{Mean and maximum test acc.}}}}\\\\\\\\\\n\")\n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "        file.write(\"mean test acc. (\\\\%) & \" + \n",
    "                   \" & & \".join([v['dense']['test_mean'] + \" & \" + v['sparse']['test_mean'] for v in max_clustering_metric_table_string.values()]) +\n",
    "                  \"\\\\\\\\\\n\")  \n",
    "        file.write(\"max. test acc. (\\\\%) & \" + \n",
    "                   \" & & \".join([v['dense']['test_max'] + \" & \" + v['sparse']['test_max'] for v in max_clustering_metric_table_string.values()]) +                   \n",
    "                   \"\\\\\\\\\\n\")\n",
    "        file.write(\"max. to mean improvement (\\\\%) & \" + \n",
    "                   \" & & \".join([v['dense']['max_to_mean'] + \" & \" + v['sparse']['max_to_mean'] for v in max_clustering_metric_table_string.values()]) +                   \n",
    "                  \"\\\\\\\\\\n\")               \n",
    "        file.write(\"\\\\bottomrule\\n\")\n",
    "        file.write(\"\\\\end{tabular}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(subfolder, \"max_clustering_metric.tex\")\n",
    "# write_metric(file_path, max_clustering_metric_table, datasets_name_and_num_classes)\n",
    "write_metric_and_max_mean(file_path, max_clustering_metric_table_string, datasets_name_and_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_p_value_md(file_path_md, p_values, num_events_list, datasets_name_and_num_classes)\n",
    "# write_p_value(file_path, p_values, num_events_list, datasets_name_and_num_classes)\n",
    "\n",
    "# # Display the content of the Markdown file as a Markdown cell\n",
    "# with open(file_path_md, \"r\") as file:\n",
    "#     markdown_content = file.read()\n",
    "\n",
    "# Markdown(markdown_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
