{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import model_factory\n",
    "from graph_data_module import GraphDataModule\n",
    "from train import Runner\n",
    "from datasets_torch_geometric.dataset_factory import create_dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"haraghi\"\n",
    "project = \"DGCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity}/{project}\")\n",
    "cfg_bare = OmegaConf.load(\"config_bare.yaml\")\n",
    "cfgs = [OmegaConf.merge(cfg_bare,OmegaConf.create(run.config)) for run in runs]\n",
    "dataset_runs = {}\n",
    "# Get the dataset names from the config file\n",
    "dataset_names = list(set([cfg.dataset.name for cfg in cfgs]))\n",
    "for dataset_name in dataset_names:\n",
    "    # Get the runs for this dataset\n",
    "\n",
    "    dataset_runs[dataset_name] = {run.id : (run,cfg) for run,cfg in zip(runs,cfgs) if \n",
    "                                  cfg.dataset.name == dataset_name and \n",
    "                                  cfg.model.name == 'EST' and \n",
    "                                  cfg.model.num_bins == 9 and\n",
    "                                  cfg.model.resnet_pretrained and\n",
    "                                  'test/acc' in run.summary and\n",
    "                                  'epoch' in run.summary and\n",
    "                                  (not cfg.model.cnn_type or cfg.model.cnn_type == \"resnet34\") and\n",
    "                                  run.summary['epoch'] > 51 }\n",
    "    \n",
    "    # dataset_runs[dataset_name] = sorted(dataset_runs[dataset_name], key=lambda r: r[0].summary['test/acc'], reverse=True)\n",
    "    \n",
    "    print(dataset_name, len(dataset_runs[dataset_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity_level(runner, gdm):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model = runner.model.to(device)\n",
    "    sparsity_level= {'train':[], 'val':[], 'test':[]}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for data in gdm.train_dataloader():   \n",
    "        data = data.to(device)\n",
    "        vox = model.quantization_layer.forward(data.to(device)).clone().detach()\n",
    "        vox_cropped = model.crop_and_resize_to_resolution(vox, model.crop_dimension) \n",
    "        sparsity_level['train'].extend([(torch.count_nonzero(v) / torch.numel(v)).item() for v in vox_cropped])\n",
    "    sparsity_level['train'] = np.array(sparsity_level['train'])[:]\n",
    "    for data in gdm.val_dataloader():   \n",
    "        data = data.to(device)\n",
    "        vox = model.quantization_layer.forward(data.to(device)).clone().detach()\n",
    "        vox_cropped = model.crop_and_resize_to_resolution(vox, model.crop_dimension) \n",
    "        sparsity_level['val'].extend([(torch.count_nonzero(v) / torch.numel(v)).item() for v in vox_cropped])\n",
    "    sparsity_level['val'] = np.array(sparsity_level['val'])[:]\n",
    "    for data in gdm.test_dataloader():   \n",
    "        data = data.to(device)\n",
    "        vox = model.quantization_layer.forward(data.to(device)).clone().detach()\n",
    "        vox_cropped = model.crop_and_resize_to_resolution(vox, model.crop_dimension) \n",
    "        sparsity_level['test'].extend([(torch.count_nonzero(v) / torch.numel(v)).item() for v in vox_cropped])\n",
    "    sparsity_level['test'] = np.array(sparsity_level['test'])[:]\n",
    "    sparsity_level['all'] = np.concatenate([sparsity_level['train'], sparsity_level['val'], sparsity_level['test']])\n",
    "    \n",
    "    return sparsity_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_results = {}\n",
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    print(\"-\"*50)\n",
    "    sparsity_results[dataset_name] = []\n",
    "    for run_id,v in dataset_runs[dataset_name].items():\n",
    "        run, cfg = v\n",
    "        print(f\"{dataset_name}:{run.summary['test/acc']:.4f} {run.summary['epoch']}\") \n",
    "\n",
    "        try:\n",
    "            artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "\n",
    "            gdm = GraphDataModule(cfg) \n",
    "            if cfg.dataset.num_classes is None:\n",
    "                cfg.dataset.num_classes = gdm.num_classes\n",
    "            \n",
    "            runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg)) \n",
    "    \n",
    "            sparsity_level = get_sparsity_level(runner, gdm)\n",
    "        except:\n",
    "            print(f\"Error for {run_id}: {dataset_name}, {cfg.model.name}, {cfg.transform.train.num_events_per_sample}.\" )\n",
    "            sparsity_level = None\n",
    "        sparsity_results[dataset_name].append((run, cfg, sparsity_level))\n",
    "\n",
    "        # delete artifact_dir\n",
    "        shutil.rmtree(artifact_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_results_filtered_NASL = [sr for sr in sparsity_results['NCARS'] if sr[2] is not None]\n",
    "for run,cfg,sparsity in sparsity_results_filtered_NASL:\n",
    "    print(run.id,run.summary['test/acc'],cfg.transform.train.num_events_per_sample, np.mean(sparsity['all']), np.std(sparsity['all']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '2yqeh948'\n",
    "for run in runs:\n",
    "    if run.id == run_id:\n",
    "        artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "        cfg = run.config\n",
    "\n",
    "runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sparsity_level.keys():\n",
    "    print(f\"{key} mean: {np.mean(sparsity_level[key])}, std: {np.std(sparsity_level[key])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    for run,cfg in dataset_runs[dataset_name]:\n",
    "        print(cfg.transform.train.num_events_per_sample, run.summary['epoch'],  cfg.wandb.experiment_name, run.id, run.summary['test/acc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(t, q):\n",
    "    B, C, H, W = t.shape\n",
    "    k = 1 + round(.01 * float(q) * (C * H * W - 1))\n",
    "    result = t.view(B, -1).kthvalue(k).values\n",
    "    return result[:,None,None,None]\n",
    "\n",
    "def create_image(representation):\n",
    "    B, C, H, W = representation.shape\n",
    "    representation = representation.view(B, 3, C // 3, H, W).sum(2)\n",
    "\n",
    "    # do robust min max norm\n",
    "    representation = representation.detach().cpu()\n",
    "    robust_max_vals = percentile(representation, 99)\n",
    "    robust_min_vals = percentile(representation, 1)\n",
    "\n",
    "    representation = (representation - robust_min_vals)/(robust_max_vals - robust_min_vals)\n",
    "    representation = torch.clamp(255*representation, 0, 255).byte()\n",
    "\n",
    "    representation = torchvision.utils.make_grid(representation)\n",
    "\n",
    "    return representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
