{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets_torch_geometric.dataset_factory import create_dataset\n",
    "import pickle\n",
    "from scipy.stats import binomtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"DVSGESTURE_TONIC\",\n",
    "                 \"NASL\",\n",
    "                 \"NCALTECH101\",\n",
    "                 \"NCARS\",\n",
    "                 \"FAN1VS3\"]\n",
    "datasets_name_and_num_classes = {\n",
    "    \"NCARS\": {\"name\": \"NCars\", \"num_classes\": 2},\n",
    "    \"NASL\": {\"name\": \"NASL\", \"num_classes\": 24},\n",
    "    \"NCALTECH101\": {\"name\": \"NCaltech101\", \"num_classes\": 101},\n",
    "    \"DVSGESTURE_TONIC\": {\"name\": \"DVS-Gesture\", \"num_classes\": 11},\n",
    "    \"FAN1VS3\": {\"name\": \"Fan1vs3\", \"num_classes\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = os.path.join(\"images\", \"paper\",\"sparsity_vs_acc\")\n",
    "if not os.path.exists(subfolder):\n",
    "    os.makedirs(subfolder)\n",
    "file_path = os.path.join(subfolder,\"p_values.tex\")\n",
    "file_path_md = os.path.join(subfolder,\"p_values.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(os.path.join(subfolder,\"class_labels.pkl\"), \"rb\") as f:\n",
    "        class_labels = pickle.load(f)\n",
    "except:  \n",
    "    class_labels = {}\n",
    "    for dataset_name in dataset_names:\n",
    "        dataset = create_dataset(\n",
    "                        dataset_path = os.path.join(\"datasets_torch_geometric\", dataset_name, \"data\"),\n",
    "                        dataset_name  = dataset_name, \n",
    "                        dataset_type = 'test'\n",
    "                    )\n",
    "        class_labels[dataset_name] = [d.y[0].item() for d in dataset]\n",
    "        assert datasets_name_and_num_classes[dataset_name][\"num_classes\"] == dataset.num_classes, f\"Number of classes in dataset {dataset_name} is not correct\"\n",
    "        print(f\"{dataset_name}: Number of samples in test set: {len(dataset)}. Number of classes: {dataset.num_classes}.\")\n",
    "    with open(os.path.join(subfolder,\"class_labels.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(class_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_dict = {}\n",
    "for dataset_name, labels in class_labels.items():\n",
    "    class_uniques, class_counts = np.unique(labels, return_counts=True)\n",
    "    class_counts_dict[dataset_name] =  class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = os.path.join(\"images\", \"paper\",\"sparsity_vs_acc\")\n",
    "with open(os.path.join(subfolder, \"full_test_mean_std.pickle\"), \"rb\") as f:\n",
    "    test_acc_results, num_events_list = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = {}\n",
    "for dataset_name in dataset_names:\n",
    "    p_values[dataset_name] = []\n",
    "    for i, num_events in enumerate(num_events_list):\n",
    "        p_values[dataset_name].append(binomtest(k=int(test_acc_results[dataset_name][i][0] * class_counts_dict[dataset_name].sum()), \n",
    "                                                 n=class_counts_dict[dataset_name].sum(), \n",
    "                                                #  p=class_counts_dict[dataset_name].max()/class_counts_dict[dataset_name].sum(),\n",
    "                                                p=1/len(class_counts_dict[dataset_name]),\n",
    "                                                 alternative='greater').pvalue)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_p_value_md(file_path, p_values, num_events_list, datasets_name_and_num_classes):\n",
    "    # Open file for writing\n",
    "    with open(file_path, \"w\") as file:\n",
    "        # Write table header\n",
    "  \n",
    "\n",
    "\n",
    "        file.write(\"| Dataset | # classes | \" +\n",
    "                   \" | \".join([str(num_events) for num_events in num_events_list]) +\n",
    "                   \"\\n\")\n",
    "        file.write(\"| --- \"*(2+len(num_events_list))+\"|\\n\")\n",
    "        # Write table rows\n",
    "        for dataset, values in p_values.items():\n",
    "            row = \"| \" + datasets_name_and_num_classes[dataset][\"name\"] + \" | \" \n",
    "            # Number of classes\n",
    "            row += str(datasets_name_and_num_classes[dataset][\"num_classes\"]) + \" | \"\n",
    "            # Test accuracies\n",
    "            for v in values:\n",
    "                if v is not None:\n",
    "                    row += \"${:.2e}$\".format(v) + \" | \"\n",
    "                else:\n",
    "                    row += \"-- | \"\n",
    "            # Write the row\n",
    "            file.write(row[:-2] + \"|\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_text = {}\n",
    "for dataset, values in p_values.items():\n",
    "    p_values_text[dataset] = []\n",
    "    for v in values:\n",
    "        if v is not None:\n",
    "            p_values_text[dataset].append(\"{:.2e}\".format(v).replace(\"0.00e+00\",\"0\"))\n",
    "        else:\n",
    "            p_values_text[dataset].append(\"---\")\n",
    "print(p_values_text)\n",
    "with open(os.path.join(subfolder,\"p_values_text.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(p_values_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_p_value(file_path, p_values, num_events_list, datasets_name_and_num_classes):\n",
    "    # Open file for writing\n",
    "    with open(file_path, \"w\") as file:\n",
    "        # Write table header\n",
    "        file.write(\"\\\\begin{tabular}{\"+(\"c\"*(2+len(num_events_list)))+\"}\\n\")\n",
    "        file.write(\"\\\\toprule\\n\")\n",
    "        file.write(\" & & \\\\multicolumn{\"+str(len(num_events_list))+\"}{c}{\\\\# events subsampling}\\\\\\\\\\n\")\n",
    "        file.write(\"Dataset & \\\\# classes & \" +\n",
    "                   \" & \".join([str(num_events) for num_events in num_events_list]) +\n",
    "                   \"\\\\\\\\\\n\")\n",
    "        file.write(\"\\\\midrule\\n\")\n",
    "\n",
    "        # Write table rows\n",
    "        for dataset, values in p_values.items():\n",
    "            row = datasets_name_and_num_classes[dataset][\"name\"] + \" & \" \n",
    "            # Number of classes\n",
    "            row += str(datasets_name_and_num_classes[dataset][\"num_classes\"]) + \" & \"\n",
    "            # Test accuracies\n",
    "            for v in values:\n",
    "                if v is not None:\n",
    "                    row += \"${:.3f}$\".format(v) + \" & \"\n",
    "                else:\n",
    "                    row += \"-- & \"\n",
    "            # Write the row\n",
    "            file.write(row[:-2] + \"\\\\\\\\\\n\")\n",
    "\n",
    "        # Write table footer\n",
    "        file.write(\"\\\\bottomrule\\n\")\n",
    "        file.write(\"\\\\end{tabular}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_p_value_md(file_path_md, p_values, num_events_list, datasets_name_and_num_classes)\n",
    "write_p_value(file_path, p_values, num_events_list, datasets_name_and_num_classes)\n",
    "\n",
    "# Display the content of the Markdown file as a Markdown cell\n",
    "with open(file_path_md, \"r\") as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "Markdown(markdown_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
