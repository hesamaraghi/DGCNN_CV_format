{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import copy\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import model_factory\n",
    "from graph_data_module import GraphDataModule\n",
    "from train import Runner\n",
    "from datasets_torch_geometric.dataset_factory import create_dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"haraghi\"\n",
    "project = \"DGCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52630bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity}/{project}\")\n",
    "cfg_bare = OmegaConf.load(\"config_bare.yaml\")\n",
    "cfgs = [OmegaConf.merge(cfg_bare,OmegaConf.create(run.config)) for run in runs]\n",
    "dataset_runs = {}\n",
    "# Get the dataset names from the config file\n",
    "dataset_names = list(set([cfg.dataset.name for cfg in cfgs]))\n",
    "for dataset_name in dataset_names:\n",
    "    # Get the runs for this dataset\n",
    "\n",
    "    dataset_runs[dataset_name] = {run.id : (run,cfg) for run,cfg in zip(runs,cfgs) if \n",
    "                                  cfg.dataset.name == dataset_name and \n",
    "                                  cfg.model.name == 'EST' and \n",
    "                                  cfg.model.num_bins == 9 and\n",
    "                                  cfg.model.resnet_pretrained and\n",
    "                                #   'test/acc' in run.summary and\n",
    "                                #   'epoch' in run.summary and\n",
    "                                  (not cfg.model.cnn_type or cfg.model.cnn_type == \"resnet34\") and\n",
    "                                #   run.summary['epoch'] > 51 \n",
    "                                    \"1vlnuera\" in run.id\n",
    "                                  }\n",
    "    \n",
    "    # dataset_runs[dataset_name] = sorted(dataset_runs[dataset_name], key=lambda r: r[0].summary['test/acc'], reverse=True)\n",
    "    \n",
    "    print(dataset_name, len(dataset_runs[dataset_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    # Use DDP training by default, even for CPU training\n",
    "    # strategy=\"ddp_notebook\",\n",
    "    devices=torch.cuda.device_count(),\n",
    "    accelerator=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events_per_sample = {}\n",
    "num_events_per_sample_unique = {}\n",
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    print(\"-\"*50)\n",
    "    num_events_per_sample[dataset_name] = []\n",
    "    for run_id, v in dataset_runs[dataset_name].items():\n",
    "        run,cfg = v\n",
    "        neps = cfg.transform.test.num_events_per_sample   \n",
    "        if neps is not None and neps < 1500 and (neps & (neps - 1)) == 0:\n",
    "            num_events_per_sample[dataset_name].append(cfg.transform.test.num_events_per_sample) \n",
    "        elif neps is None and cfg.transform.test.random_num_events_per_sample.transform:\n",
    "            num_events_per_sample[dataset_name].append(\"random\")\n",
    "    num_events_per_sample_unique[dataset_name] = list(set(num_events_per_sample[dataset_name]))\n",
    "    print(num_events_per_sample_unique[dataset_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c304d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'sx3f1cu2'\n",
    "cfg = dataset_runs['FAN1VS3'][run_id][1]\n",
    "gdm = GraphDataModule(cfg) \n",
    "if cfg.dataset.num_classes is None:\n",
    "    cfg.dataset.num_classes = gdm.num_classes\n",
    "artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "\n",
    "runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "run_id = '1vlnuera'\n",
    "cfg = dataset_runs['NASL'][run_id][1]\n",
    "gdm = GraphDataModule(cfg) \n",
    "if cfg.dataset.num_classes is None:\n",
    "    cfg.dataset.num_classes = gdm.num_classes\n",
    "artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "# artifact_dir = glob(osp.join(\"DGCNN\", run_id, \"checkpoints\",\"*\"))\n",
    "# assert len(artifact_dir) == 1\n",
    "# artifact_dir = artifact_dir[0]\n",
    "runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e060227",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results = []\n",
    "loss_results = []\n",
    "for _ in range(400):\n",
    "        results  = trainer.test(model=runner, datamodule=gdm, verbose=0)\n",
    "        acc_results.append(results[0]['test/acc'])\n",
    "        loss_results.append(results[0]['test/loss'])\n",
    "        \n",
    "plt.hist(loss_results, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss_results, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9415752",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test_sparsity_sensitivity_nasl_randome_inverse_sampling.pt\"\n",
    "\n",
    "if os.path.isfile(file_path):\n",
    "    sparsity_results = torch.load(file_path)\n",
    "else:\n",
    "    sparsity_results = {}\n",
    "    \n",
    "num_try = 5\n",
    "for dataset_name in dataset_names:\n",
    "    print(\"-\"*50)\n",
    "    print(dataset_name)\n",
    "    print(\"-\"*50)\n",
    "    if 'NASL' not in dataset_name:\n",
    "        continue\n",
    "    if dataset_name not in sparsity_results:\n",
    "        sparsity_results[dataset_name] = {}\n",
    "    for run_id,v in dataset_runs[dataset_name].items():\n",
    "        if run_id in sparsity_results[dataset_name]:\n",
    "            continue\n",
    "        run, cfg = v\n",
    "        # print(f\"{dataset_name}:{run.summary['test/acc']:.4f} {run.summary['epoch']}\")\n",
    "        trained_num_events = cfg.transform.train.num_events_per_sample\n",
    "        print(f'trained #events: {trained_num_events}') \n",
    "        sparsity_results[dataset_name][run_id] = {}\n",
    "        sparsity_results[dataset_name][run_id]['trained_num_events'] = trained_num_events\n",
    "        # sparsity_results[dataset_name][run_id]['summary_test_acc'] = run.summary['test/acc']\n",
    "        sparsity_results[dataset_name][run_id]['model'] = cfg.model.name\n",
    "        sparsity_results[dataset_name][run_id]['tested_num_events'] = {}\n",
    "        artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "        # artifact_dir = glob(osp.join(\"DGCNN\", run_id, \"checkpoints\",\"*\"))\n",
    "        # assert len(artifact_dir) == 1\n",
    "        \n",
    "  \n",
    "        gdm = GraphDataModule(cfg) \n",
    "        if cfg.dataset.num_classes is None:\n",
    "            cfg.dataset.num_classes = gdm.num_classes\n",
    "\n",
    "        runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg)) \n",
    "        # runner = Runner.load_from_checkpoint(artifact_dir[0], cfg=cfg, model=model_factory.factory(cfg))    \n",
    "  \n",
    "        for neps in [8,16,32,64,128,256,512,1024,2048]:\n",
    "            sparsity_results[dataset_name][run_id]['tested_num_events'][neps] = []\n",
    "            print(f'tested #events: {neps}') \n",
    "            cfg_new = copy.deepcopy(cfg)        \n",
    "            cfg_new.transform.test.num_events_per_sample = neps\n",
    "            gdm = GraphDataModule(cfg_new) \n",
    "            if cfg_new.dataset.num_classes is None:\n",
    "                cfg_new.dataset.num_classes = cfg_new.num_classes\n",
    "\n",
    "            for _ in range(num_try):\n",
    "                results  = trainer.test(model=runner, datamodule=gdm, verbose=0)\n",
    "                sparsity_results[dataset_name][run_id]['tested_num_events'][neps].append(results)\n",
    "                torch.save(sparsity_results, file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_results = torch.load(f\"sparsity_sensitivity_results_all_.pt\")\n",
    "num_try = 5\n",
    "for dataset_name in dataset_names:\n",
    "    print(\"-\"*50)\n",
    "    print(dataset_name)\n",
    "    print(\"-\"*50)\n",
    "    if 'FAN' not in dataset_name:\n",
    "        continue\n",
    "    if dataset_name not in sparsity_results:\n",
    "        sparsity_results[dataset_name] = {}\n",
    "    for run_id,v in dataset_runs[dataset_name].items():\n",
    "        if run_id in sparsity_results[dataset_name]:\n",
    "            continue\n",
    "        run, cfg = v\n",
    "        print(f\"{dataset_name}:{run.summary['test/acc']:.4f} {run.summary['epoch']}\")\n",
    "        trained_num_events = cfg.transform.train.num_events_per_sample\n",
    "        print(f'trained #events: {trained_num_events}') \n",
    "        sparsity_results[dataset_name][run_id] = {}\n",
    "        sparsity_results[dataset_name][run_id]['trained_num_events'] = trained_num_events\n",
    "        sparsity_results[dataset_name][run_id]['summary_test_acc'] = run.summary['test/acc']\n",
    "        sparsity_results[dataset_name][run_id]['model'] = cfg.model.name\n",
    "        sparsity_results[dataset_name][run_id]['tested_num_events'] = {}\n",
    "        artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "  \n",
    "        gdm = GraphDataModule(cfg) \n",
    "        if cfg.dataset.num_classes is None:\n",
    "            cfg.dataset.num_classes = gdm.num_classes\n",
    "\n",
    "        runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg))   \n",
    "  \n",
    "        for neps in num_events_per_sample_unique[dataset_name]:\n",
    "            sparsity_results[dataset_name][run_id]['tested_num_events'][neps] = []\n",
    "            print(f'tested #events: {neps}') \n",
    "            cfg_new = copy.deepcopy(cfg)        \n",
    "            cfg_new.transform.test.num_events_per_sample = neps\n",
    "            gdm = GraphDataModule(cfg_new) \n",
    "            if cfg_new.dataset.num_classes is None:\n",
    "                cfg_new.dataset.num_classes = cfg_new.num_classes\n",
    "\n",
    "            for _ in range(num_try):\n",
    "                results  = trainer.test(model=runner, datamodule=gdm, verbose=0)\n",
    "                sparsity_results[dataset_name][run_id]['tested_num_events'][neps].append(results)\n",
    "            torch.save(sparsity_results, f\"sparsity_sensitivity_results_all_.pt\")\n",
    "        #     print(f\"Error for {run_id}: {dataset_name}, {cfg.model.name}, {cfg.transform.train.num_events_per_sample}.\" )\n",
    "        #     dgsdk\n",
    "        #     sparsity_level = None\n",
    "        # cfg_new = copy.deepcopy(cfg)        \n",
    "        # cfg_new.transform.test.num_events_per_sample = \n",
    "        # gdm = GraphDataModule(cfg) \n",
    "        # if cfg.dataset.num_classes is None:\n",
    "        #     cfg.dataset.num_classes = gdm.num_classes\n",
    "\n",
    "        #     artifact_dir = WandbLogger.download_artifact(artifact=f\"{entity}/{project}/model-{run_id}:best\")\n",
    "\n",
    "       \n",
    "            \n",
    "        #     runner = Runner.load_from_checkpoint(osp.join(artifact_dir,\"model.ckpt\"), cfg=cfg, model=model_factory.factory(cfg)) \n",
    "    \n",
    "        #     sparsity_level = get_sparsity_level(runner, gdm)\n",
    "        #     print(f\"Error for {run_id}: {dataset_name}, {cfg.model.name}, {cfg.transform.train.num_events_per_sample}.\" )\n",
    "        #     dgsdk\n",
    "        #     sparsity_level = None\n",
    "        # sparsity_results[dataset_name].append((run, cfg, sparsity_level))\n",
    "\n",
    "        # # delete artifact_dir\n",
    "        shutil.rmtree(artifact_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
