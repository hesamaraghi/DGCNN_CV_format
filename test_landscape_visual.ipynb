{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from glob import glob\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import model_factory\n",
    "from graph_data_module import GraphDataModule\n",
    "from train import Runner\n",
    "from datasets_torch_geometric.dataset_factory import create_dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.config_utils import recursive_dict_compare\n",
    "from datatransforms.event_transforms import FilterNodes\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"haraghi\"\n",
    "project = \"sweep EST (FAN1VS3) (multi val test num 20)\"\n",
    "# project = \"sweep EST (FAN1VS3) 25000 (multi val test num 20)\"\n",
    "# project = \"sweep_EST_NCALTECH101_1024_multi20\"\n",
    "run_id = 'm529xtfz'\n",
    "\n",
    "\n",
    "checkpoint_file = glob(osp.join(project, run_id, \"checkpoints\",\"*\"))\n",
    "if checkpoint_file:\n",
    "    assert len(checkpoint_file) == 1\n",
    "    checkpoint_file = checkpoint_file[0]\n",
    "    print(\"loading checkpoint from\", checkpoint_file)\n",
    "else:\n",
    "    checkpoint_file = glob(osp.join(run_id, \"checkpoints\",\"*\"))\n",
    "    if checkpoint_file:\n",
    "        assert len(checkpoint_file) == 1\n",
    "        checkpoint_file = checkpoint_file[0]\n",
    "        print(\"loading checkpoint from\", checkpoint_file)\n",
    "    else:\n",
    "        raise ValueError(\"no checkpoint file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_bare = OmegaConf.load(\"config_bare.yaml\")\n",
    "config = api.run(osp.join(entity, project, run_id)).config\n",
    "cfg = OmegaConf.create(config) \n",
    "\n",
    "if \"cfg_path\" in cfg.keys():\n",
    "    print(cfg.cfg_path)\n",
    "    cfg_file = OmegaConf.merge(cfg_bare,OmegaConf.load(cfg.cfg_path))\n",
    "else:\n",
    "    cfg_file = cfg\n",
    "cfg = OmegaConf.merge(cfg_file, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(50*\"=\")\n",
    "print(\"cfg_file\")\n",
    "print(50*\"-\")\n",
    "print(yaml.dump(recursive_dict_compare(OmegaConf.to_object(cfg),OmegaConf.to_object(cfg_file)), default_flow_style=False))\n",
    "print(50*\"=\")\n",
    "print(\"cfg\")\n",
    "print(50*\"-\")\n",
    "print(yaml.dump(recursive_dict_compare(OmegaConf.to_object(cfg_file),OmegaConf.to_object(cfg)), default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.num_workers = 2\n",
    "gdm = GraphDataModule(cfg)\n",
    "cfg.dataset.num_classes = gdm.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_address = osp.join(\"landscape_plots\",project,run_id)\n",
    "if not osp.exists(folder_address):\n",
    "    os.makedirs(folder_address)\n",
    "\n",
    "trainloader = gdm.train_dataloader()\n",
    "torch.save(trainloader, osp.join(folder_address,\"trainloader.pt\"))\n",
    "testloader = gdm.test_dataloader()[0]\n",
    "torch.save(testloader, osp.join(folder_address,\"testloader.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.save(cfg, osp.join(folder_address, \"cfg.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_factory.factory(cfg)\n",
    "runner = Runner.load_from_checkpoint(checkpoint_path = checkpoint_file, cfg=cfg, model=model)\n",
    "torch.save(runner.model.state_dict(),osp.join(folder_address,\"state_dict.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    enable_progress_bar=True,\n",
    "    # Use DDP training by default, even for CPU training\n",
    "    # strategy=\"ddp_notebook\",\n",
    "    devices=torch.cuda.device_count(),\n",
    "    accelerator=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runner.cfg.model)\n",
    "results = trainer.test(runner, datamodule=gdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_file = \"multiple_train_loss_*.h5\"\n",
    "\n",
    "folder_address = osp.join(\"landscape_plots\",project,run_id)\n",
    "desired_args = [\n",
    "    '--log', '--cuda', '--mpi', '--dataset', 'from_file', '--model', 'EST',\n",
    "    '--x=-1:1:101',\n",
    "    '--dir_type', 'states', '--xignore', 'biasbn', '--xnorm', 'filter',\n",
    "    '--model_folder', folder_address,\n",
    "    '--model_file', osp.join(folder_address,\"state_dict.pt\"),\n",
    "    '--testloader', osp.join(folder_address,\"testloader.pt\"),\n",
    "    '--trainloader', osp.join(folder_address,\"trainloader.pt\"),\n",
    "    '--surf_file', osp.join(folder_address,surf_file)\n",
    "]\n",
    "\n",
    "dir_file_list = glob(osp.join(folder_address,\"state_dict.pt*.h5\"))\n",
    "if dir_file_list:\n",
    "    assert len(dir_file_list) == 1\n",
    "    desired_args.append(['--dir_file', dir_file_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_script.py\n",
    "import subprocess\n",
    "\n",
    "# Construct the command to run the first script with the desired arguments\n",
    "command = ['python', 'loss-landscape/plot_surface.py'] + desired_args\n",
    "\n",
    "# Call the first script with subprocess\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class FilterNodesFixedEvents(FilterNodes):\n",
    "    \n",
    "    def __init__(self, num_indices):\n",
    "        super().__init__()\n",
    "        self.num_indices = num_indices\n",
    "        self.indices = None\n",
    "\n",
    "    def get_indices(self,data):\n",
    "        if self.indices is None:\n",
    "            self.indices = torch.randperm(data.num_nodes)[:self.num_indices]\n",
    "        return self.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"FAN1VS3\"\n",
    "dataset_path  = osp.join('datasets_torch_geometric', dataset_name, 'data')\n",
    "num_events_per_sample = cfg.transform.train.num_events_per_sample\n",
    "dataset = create_dataset(\n",
    "                dataset_path = dataset_path,\n",
    "                dataset_name  = dataset_name,\n",
    "                dataset_type = 'test',\n",
    "                transform = T.Compose([FilterNodesFixedEvents(num_events_per_sample)]),\n",
    "                num_workers=2\n",
    "            )\n",
    "dataset_random = create_dataset(\n",
    "                dataset_path = dataset_path,\n",
    "                dataset_name  = dataset_name,\n",
    "                dataset_type = 'test',\n",
    "                transform = T.Compose([T.FixedPoints(num_events_per_sample, replace = False, allow_duplicates = True)]),\n",
    "                num_workers=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_0 = DataLoader(\n",
    "     [dataset[0]],\n",
    "     batch_size=1,\n",
    "     shuffle=False,\n",
    "     num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataloader_0, osp.join(folder_address,\"trainloader_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_loaded_0 = torch.load(osp.join(folder_address,\"trainloader_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataloader_0:\n",
    "    print(data.pos.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in loader_loaded_0:\n",
    "    print(data.pos.int())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
